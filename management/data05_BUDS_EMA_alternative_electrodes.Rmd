---
title: "Data prep script 5: Importing and combining EMA data"
author: "Brent Rappaport"
date: "`r format(Sys.time(),  '%Y-%m-%d')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
subtitle: Template Rmd
editor_options:
  chunk_output_type: console
toc: yes
---

# About
This script filter and scores the self-report data from BUDS study: Bullying, Unsupportive family/peers, Discrimination, and Social feedback study using data from PREDICT project collaboration between Northwestern (PI: Shankman) and Columbia (PI: Auerbach).

# Get Setup
## Clear everything & set width
```{r}
rm(list=ls())     #Remove everything from environment
# .rs.restartR()    #Restart R session

knitr::opts_chunk$set(set.seed(312), echo=FALSE, results='hide', message=FALSE, warning=FALSE, error=FALSE)
    options(width=80) #Set width
    cat("\014")       #Clear Console
```

## Load Libraries
```{r}
  library(knitr)      #allows rmarkdown files
  library(haven)      #helps import stata
  library(questionr)  #allows lookfor function
  library(broom)      #nice statistical output
  library(here)       #nice file paths
  library(expss)      #labeling variables/values
  library(psych)      #used for statistical analyses
  library(ggplot2)    #creates plots
  library(MASS)
  library(papaja)     #generate APA documents
  library(Hmisc)
  library(misty)      #ordinal Cronbach's alpha
  library(lavaan)     #SEM
  library(papaja)
  library(pscl)       # for zero inflated models
  library(lme4)
  library(lmerTest)
  library(bbmle)
  library(marginaleffects)
  library(bestNormalize) # for normalizing data
  library(dplyr)
  library(workflowr)  #helps with workflow

select <- dplyr::select
```

## Get the Working Directory
```{r}
  here::i_am("./management/data05_BUDS_EMA.Rmd")
```

## Load EMA data
Remember to immediately rename and remove. Avoid overwriting old data.
```{r, eval=F}
subjects <- c(1000,
1001,
1004,
1006,
1010,
1012,
1014,
1017,
1021,
1022,
1023,
1024,
1025,
1026,
1027,
1029,
1030,
1031,
1033,
1035,
1036,
1037,
1039,
1040,
1043,
1044,
1046,
1047,
1048,
1049,
1050,
1052,
1053,
1054,
1055,
1057,
1058,
1059,
1060,
1061,
1063,
1064,
1065,
1066,
1067,
1068,
1069,
1070,
1071,
1072,
1074,
1075,
1077,
1078,
1079,
1080,
1081,
1082,
1084,
1085,
1086,
1087,
1088,
1089,
1090,
1091,
1094,
1095,
1096,
1098,
1099,
1100,
1101,
1102,
1103,
1104,
1105,
1106,
1107,
1108,
1109,
1110,
1111,
1112,
1114,
1115,
1117,
1118,
1119,
1120,
1121,
1122,
1123,
1124,
1125,
1126,
9001,
9003,
9004,
9006,
9007,
9008,
9010,
9013,
9014,
9015,
9017,
9018,
9019,
9020,
9021,
9022,
9024,
9026,
9027,
9028,
9030,
9031,
9033,
9034,
9035,
9037,
9038,
9039,
9040,
9042,
9043,
9044,
9045,
9046,
9048,
9049,
9051,
9052,
9053,
9055,
9057,
9059,
9060,
9061,
9062,
9063,
9067,
9068,
9069,
9070,
9072,
9075,
9076,
9077,
9078,
9079,
9080,
9081,
9082,
9083,
9084,
9085,
9087,
9088,
9089,
9091,
9092,
9093,
9094,
9096,
9097,
9098,
9099,
9100)

# df_ema_daily <- read.csv(here::here("./data/PREDICT_daily_merged_all.csv"), header=TRUE)
# df_ema <- read.csv(here::here("./data/PREDICT_EMA_merged_all.csv"), header=TRUE)
```

## Load ERP data
```{r}
load(here::here("./data/BUDS_df_ERP.RData"))
```

# EMA
```{r}
df_ema_daily_raw <- read.csv(here::here("./data/PREDICT_daily_merged_all.csv"), header=TRUE)
df_ema <- read.csv(here::here("./data/PREDICT_EMA_merged_all.csv"), header=TRUE)

df_ema_summary <- df_ema %>%
  mutate(ID = subject_id) %>%
  group_by(ID) %>%
  mutate(angry_mean = mean(angry, na.rm=T),
         anxious_mean = mean(anxious, na.rm=T),
         excited_mean = mean(excited, na.rm=T),
         happy_mean = mean(happy, na.rm=T),
         rejected_mean = mean(rejected, na.rm=T),
         sad_mean = mean(sad, na.rm=T),
         supported_mean = mean(supported, na.rm=T),
         sharedEmotions_mean = mean(sharedEmotions, na.rm=T),
         connect_mean = mean(connect, na.rm=T),
         messages_mean = mean(messages, na.rm=T),
         conversations_mean = mean(conversations, na.rm=T),
         covidIsolated_mean = mean(covidIsolated, na.rm=T),
         covidStressed_mean = mean(covidStressed, na.rm=T)) %>%
  ungroup()

daily <- df_ema_daily_raw %>%
  # select(subject_id, daily, dt_local, tm_start, tm_end) %>%
  filter(complete.cases(daily))
```

### Intensives: Lilian's cleaning code
```{r}
ema <- df_ema
# check whether overlapping times
dups.index1 = duplicated(ema[, c("subject_id", "tm_start")])
dups.index2 = duplicated(ema[, c("subject_id", "tm_start")], fromLast = T)
dups = ema[dups.index1, ] %>%
  rbind(ema[dups.index2, ]) %>%
    arrange(subject_id, tm_start) ## same rating, same id_file --> remove duplicated ratings

ema = ema %>%
  distinct(subject_id, tm_start, .keep_all = T)

# remove non-baseline times
baseline <- ema %>%
  dplyr::arrange(subject_id, tm_start) %>%
  dplyr::group_by(subject_id) %>%
  dplyr::mutate(daysFrom = difftime(as.Date(tm_start), as.Date(tm_start[1]), units = "days")) %>%
  dplyr::mutate(daysFrom = as.numeric(daysFrom)) %>%
  dplyr::filter(daysFrom <= 7) %>%
  dplyr::ungroup()

# remove responses where all ratings were NA
baseline = baseline %>%
  filter(!(is.na(angry) & is.na(anxious) & is.na(excited) & is.na(happy) & is.na(rejected) & is.na(sad) & is.na(supported)
           & is.na(sharedEmotions) & is.na(connect) & is.na(messages) & is.na(conversations)))

#Carelessness: (a) an EMA completed in which the participant spent less than an average of 1 s per item; (b) any EMA in which the within-EMA standard deviation is less than 5 (when using a 0–100 scale); and (c) any EMA in which more than 60% of items are given the same modal score (Heller et al., 2021)
# I’ve only removed responses where the same score was given to everything
check = baseline %>%
  mutate(secPerItem = as.numeric(difftime(tm_end, tm_start, units = "secs"))/rowSums(!is.na(baseline %>% select(angry:restful)))) %>%
  mutate(emoSD = matrixStats::rowSds(as.matrix(.[,c("angry", "anxious", "excited", "happy", "rejected", "sad", "supported",
                                                    "sharedEmotions","connect","messages", "conversations")])))
remove = check %>% filter(emoSD == 0)

baseline = baseline %>%
  anti_join(remove %>% select(id_file:daysFrom)) %>%
  arrange(subject_id, tm_start) %>%
  mutate(date = as.Date(tm_start),
         hour = as.numeric(format(tm_start, format = "%H")),
         wday = format(tm_start, format = "%wday")) %>%
  mutate(EMA.baseline = factor(paste0(wday, hour)))

# multiples within a time block
## skipped
# baseline = baseline %>%
#   mutate(block = ifelse(hour<11, "morning",
#                         ifelse(hour<=16, "afternoon",
#                                ifelse(hour<=18, "evening",
#                                       ifelse(hour<=23, "night", NA)))))

check = baseline %>% dplyr::count(subject_id, date, block) %>% arrange(-n)

# remove people with < 3 responses
resp.rate = baseline %>% dplyr::count(subject_id)
remove = resp.rate %>% filter(n < 3)
baseline = baseline %>% 
  filter(!(subject_id %in% remove$subject_id)) %>%
  mutate(pa = rowMeans(.[, c("happy", "excited", "supported")], na.rm = F),
         na = rowMeans(.[, c("angry", "anxious", "sad", "rejected")], na.rm = F),
         effort = rowMeans(.[, c("sharedEmotions", "connect")], na.rm = F),
         future = rowMeans(.[, c("messages", "conversations")], na.rm = F),
         ID = subject_id)

missing_na <- baseline %>%
  group_by(ID,daysFrom) %>%
  reframe(missing_na = sum(is.na(na))) %>%
  arrange(desc(missing_na))
```

```{r}
## make time-varying (daily or within-day) variables
df_ema_all <- df_ema_summary %>%
  mutate(ID = subject_id) %>%
  filter(cont_days<=7) %>%
  group_by(ID, cont_days) %>% 
  mutate(nSurveys_daily = sum(complete.cases(dt_local)),
         nConsecPairs_daily = sum(complete.cases(dt_local) & complete.cases(lag(dt_local))),
         time_of_day = case_match(slot, "Morning" ~ 1,
                                        "Afternoon" ~ 2,
                                        "Evening" ~ 3,
                                        "Night" ~ 4)) %>%
  mutate(
         ## center within day (within people; .cwd = centered within day)
         time_of_day.cwd = time_of_day - mean(time_of_day, na.rm = TRUE),
         ## calculate amount of time between surveys (excluding overnight lags and missing surveys)
         SecsSinceLastCompleted = as.numeric(difftime(tm_end, dplyr::lag(zoo::na.locf(tm_end, na.rm = FALSE)), units = "secs")),
         MinsSinceLastCompleted = SecsSinceLastCompleted / 60) %>% 
  ungroup() %>%
## Create participant-level variables for EMA completion rates
  group_by(ID) %>% 
  mutate(nSurveysTotal = sum(!is.na(dt_local)),
         ComplianceRate = nSurveysTotal / 28) %>% 
  ungroup() %>%
## Center EMA variables
# Person-mean centering (more generally, "centering within cluster")
# .pm = person mean
# .cwp = centered within person
  group_by(ID) %>%
  mutate(
    across(.cols = c('happy', 'angry', 'sad', 'anxious', 'rejected', 'supported', 'sharedEmotions', 'connect', 'messages', 'conversations'),
           .fns = list('pm' = ~ mean(., na.rm = TRUE), # create person-level means
                       'psd' = ~ sd(., na.rm = TRUE), # create person-level SDs (variability)
                       'cwp' = ~ . - mean(., na.rm = TRUE)), # create person-centered variables
           .names = '{.col}.{.fn}')
  ) %>%
  ungroup() %>%
  ## THIS PART WAS NOT ORIGINALLY LEADING VALUES PROPERLY
  ## for that reason, there is this odd workaround using transform instead of mutate and without
## Make lagged and leaded variables for instability and inertia analyses
  group_by(ID, cont_days) %>% # note: grouping by participant *and day* excludes overnight lags
  transform(lead.happy = dplyr::lead(happy, n = 1L, default=NA),
            lead.angry = dplyr::lead(angry, n = 1L, default=NA),
            lead.sad = dplyr::lead(sad, n = 1L, default=NA),
            lead.rejected = dplyr::lead(rejected, n = 1L, default=NA),
            lead.anxious = dplyr::lead(anxious, n = 1L, default=NA),
            lead.supported = dplyr::lead(supported, n = 1L, default=NA),
            lead.sharedEmotions = dplyr::lead(sharedEmotions, n = 1L, default=NA),
            lead.connect = dplyr::lead(connect, n = 1L, default=NA),
            lead.messages = dplyr::lead(messages, n = 1L, default=NA),
            lead.conversations = dplyr::lead(conversations, n = 1L, default=NA)) %>%
  transform(lead.happy = ifelse(time_of_day==4, NA, lead.happy),
            lead.angry = ifelse(time_of_day==4, NA, lead.angry),
            lead.sad = ifelse(time_of_day==4, NA, lead.sad),
            lead.rejected = ifelse(time_of_day==4, NA, lead.rejected),
            lead.anxious = ifelse(time_of_day==4, NA, lead.anxious),
            lead.supported = ifelse(time_of_day==4, NA, lead.supported),
            lead.sharedEmotions = ifelse(time_of_day==4, NA, lead.sharedEmotions),
            lead.connect = ifelse(time_of_day==4, NA, lead.connect),
            lead.messages = ifelse(time_of_day==4, NA, lead.messages),
            lead.conversations = ifelse(time_of_day==4, NA, lead.conversations)) %>%
  
  mutate(across(.cols = c('happy', 'angry', 'sad', 'anxious', 'rejected', 'supported', 'sharedEmotions', 'connect', 'messages', 'conversations', # uncentered EMA variables
                     paste0(c('happy', 'angry', 'sad', 'anxious', 'rejected', 'supported', 'sharedEmotions', 'connect', 'messages', 'conversations'), '.cwp')), # person-centered EMA variables
           .fns = list('lag' = ~ lag(., n = 1L)), # create lagged affect (at time t-1)
           .names = '{.fn}.{.col}')) %>%
    ungroup()

# View(df_ema_all[,c("ID","cont_days","time_of_day","sad","lead.sad","lag.sad")])
# View(dat_all[,c("sub","day","time_of_day","happy_EMA","lead.happy_EMA")])
```

## Descriptives
```{r, eval=F}
## Create a dataframe with 1 row per person
dat_all_1rowPerPerson <- df_ema_all %>% 
  filter(!duplicated(ID)) %>% # filter so there is 1 row per person
  dplyr::select(-c(happy, angry, sad, # remove some of the variables that vary within-person (should remove them all to avoid confusion)
            starts_with('lead.'), starts_with('lag.'), ends_with('.cwp'))) 

## Analyzable N
dat_all_1rowPerPerson %>% with(n_distinct(ID))

## calculate the average number of EMA surveys per day for each person
dat_all_1rowPerPerson2 <- dat_all_1rowPerPerson %>% 
  # full_join(df_ema_all, by="ID") %>% # Brent commented this out, I don't think it's needed
              dplyr::distinct(ID, cont_days, .keep_all = TRUE) %>% # filter so there's one row per person-day
              group_by(ID,site,nSurveysTotal,ComplianceRate) %>%
              reframe(nSurveys_daily.pm = mean(nSurveys_daily, na.rm = TRUE),
                        nConsecPairs.psum = sum(nConsecPairs_daily, na.rm = TRUE),
                        nConsecPairs_daily.pm = mean(nConsecPairs_daily, na.rm = TRUE))

## table of participant characteristics (demographics, etc.)
tableone::CreateTableOne(vars = c('nSurveysTotal', 'ComplianceRate', 'nSurveys_daily.pm',
                                  'nConsecPairs.psum', 'nConsecPairs_daily.pm'),
                         data = dat_all_1rowPerPerson2,
                         strata = 'site',
                         addOverall = TRUE)
```

## Prediction of mean levels
### Merge data
#### Intensives
```{r}
# df_50150_fz_long_ema <- full_join(df_50150_fz_long_strain, baseline, by="ID", relationship="many-to-many")
# df_150275_cz_long_ema <- full_join(df_150275_cz_long_strain, baseline, by="ID", relationship="many-to-many")
# df_275425_pz_long_ema <- full_join(df_275425_pz_long_strain, baseline, by="ID", relationship="many-to-many")
baseline <- baseline %>% select(-site)

# Function to remove duplicated ID values (just select the first row, center covariates, 
# merge with baseline data, and create residualized ERP scores)
residualizing <- function(data) {
data %>%
  # make residualized score
  filter(complete.cases(Acc_Acc)) %>%
  mutate(AA_AR = rstandard(lm(Acc_Acc ~ Acc_Rej, .)),
         AR_AA = rstandard(lm(Acc_Rej ~ Acc_Acc, .))) %>%
  # merge with baseline data
  right_join(baseline, by="ID", relationship="many-to-many")
}

df_50150_fz_ema <- residualizing(df_50150_fz_strain)
df_150275_cz_ema <- residualizing(df_150275_cz_strain)
df_275425_pz_ema <- residualizing(df_275425_pz_strain)
```

# Save files
```{r}
# for (d in c(50150, 150275, 275425)) {
#   print(eval(parse(text=paste0('
#   save(df_',d,'_cz,
#   df_',d,'_cz_strain, 
#   df_',d,'_cz_ema, 
#   file=here::here("./data/df_',d,'.RData"))
#   '))))
# }

save(df_50150_fz, df_50150_fz_strain, df_50150_fz_ema, file=here::here("./data/df_50150.RData"))
save(df_150275_cz, df_150275_cz_strain, df_150275_cz_ema, file=here::here("./data/df_150275.RData"))
save(df_275425_pz, df_275425_pz_strain, df_275425_pz_ema, file=here::here("./data/df_275425.RData"))
```
