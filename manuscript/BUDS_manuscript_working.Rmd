---
title     : "Socioeconomic status and adolescent brain responses to peer feedback: Testing the impact on negative affect"
shorttitle    : "SES & brain responses to peer feedback"

author: 
  - name    : "Brent I. Rappaport"
    affiliation : "1"
    corresponding : yes  # Define only one corresponding author
    address   : "680 N. Lakeshore Drive, Suite 1520, Chicago, IL 60611"
    email   : "brent.rappaport@northwestern.edu"
    role:   # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Formal analysis"
      - "Methodology"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name    : "James E. Glazer"
    affiliation : "1"
    role:
      - "Methodology"
      - "Writing - Review & Editing"
  - name    : "Allison M. Letkiewicz"
    affiliation : "1"
    role:
      - "Writing - Review & Editing"
  - name    : "Lilian Y. Li"
    affiliation : "1"
    role:
      - "Methodology"
      - "Writing - Review & Editing"
  - name    : "Madeline M. McGregor"
    affiliation : "1"
    role:
      - "Writing - Review & Editing"
  - name    : "Lili A. Massac"
    affiliation : "2"
    role:
    - "Writing - Review & Editing"
  - name    : "Katherine Durham"
    affiliation : "2"
    role:
    - "Writing - Review & Editing"
  - name          : "Randy Auerbach"
    affiliation   : "2"
    role:
      - "Conceptualization"
      - "Fundind acquisition"
      - "Investigation"
      - "Methodology"
      - "Resources"
      - "Supervision"
      - "Writing - Review & Editing"
  - name          : "Stewart A. Shankman"
    affiliation   : "1"
    role:
      - "Conceptualization"
      - "Fundind acquisition"
      - "Investigation"
      - "Methodology"
      - "Resources"
      - "Supervision"
      - "Writing - Review & Editing"

affiliation:
  - id    : "1"
    institution : "Department of Psychiatry, Feinberg School of Medicine, Northwestern University"
  - id    : "2"
    institution : "Columbia University"

abstract: |
  *Background*: Lower socioeconomic status (SES) is a potent risk factor for psychopathology in youth, however the mechanisms linking them are yet unknown. One potential neural mechanism is aberrant brain responding to peer acceptance and rejection. This study will test whether SES (operationalized as neighborhood area deprivation) is 1) related to brain responses to peer feedback, and 2) moderates the relationship between brain responses to peer feedback and affect measured outside of the lab. *Methods*: 170 adolescent participants (ages 13-19) completed an event-related potential (ERP) task where they received accepting or rejecting feedback from peers, a week of ecological momentary assessment (EMA) reporting on their positive and negative affect, and a self-report of discrimination (adolescent discrimination distress index). *Results*: Lower SES was related to blunted responses to acceptance. Moreover, lower in SES was related to a more positive relationship between brain responses to rejection and EMA reported negative affect. *Conclusions*: SES may be linked to psychopathology via heightened sensitivity to rejection, and/or blunted responses acceptance. These findings suggest that prevention and intervention efforts targeting sensitivity to social feedback may reduce risk for internalizing disorders in low SES youth.
  
keywords    : "social feedback, socioeconomic status, area deprivation, negative affect, discrimination"

bibliography  : "BUDS.bib"
floatsintext  : yes
linenumbers   : no
draft         : no
mask          : no
figurelist    : no
tablelist     : no
footnotelist  : no
csl     : 'biological-psychiatry.csl'
# csl     : 'apa7.csl'
documentclass   : "apa7"
output        : papaja::apa6_word
  
editor_options: 
  markdown: 
  wrap: sentence
  
header-includes:
  - \usepackage{setspace}
  - \AtBeginEnvironment{tabular}{\singlespacing}
  - \AtBeginEnvironment{lltable}{\singlespacing}
  - \addtolength{\tabcolsep}{6pt}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1.5}}
  
  - \raggedbottom
  # - \usepackage{helvet}
  # - \renewcommand{\familydefault}{\sfdefault}
---

```{r analysis-preferences}
knitr::opts_chunk$set(set.seed(312), warning=FALSE, message=FALSE, include=FALSE, results='hide')
  options(width=80, Ncpus = 6, mc.cores=6, max.print=1000000, scipen = 999) #Set width, multiple cores, and not to use scientific notation
  rm(list=ls())   #Remove everything from environment
  cat("\014")   #Clear Console

  # library(knitr)  #allows rmarkdown files
  library(haven)  #helps import stata
  library(expss)  #labeling variables/values
  library(broom.mixed)  #nice statistical output
  library(here)   #nice file paths
  library(psych)  #used for statistical analyses
  library(Hmisc)
  library(purrr)
  library(haven)  #to import SPSS files
  library(MASS)   #to create residualized scores
# Models
  library(lmerTest)
  library(glmmTMB)
# Plotting
  library(ggplot2)  #creates plots
  library(ggpubr)
  library(ggeffects)
  library(sjPlot)
  library(sjPlot)
  library(marginaleffects)
  library(interactions)
  library(latex2exp)
  library(emmeans) # testing simple slopes

  library(datawizard)
  library(performance)
  library(xfun)
  library(Rmisc)
  library(vtable)
# General tools
  library(tidyverse)  #plotting/cleaning, etc.
  library(scipub) #demo table
  library(r2symbols) # symbols inline text
  library(papaja)
  library(workflowr)  #helps with workflow
  library(dplyr)

here <- here::here
here::i_am("BUDS_manuscript_working.Rmd")

filter <- dplyr::filter

r_refs("BUDS.bib")
```

```{r Load data}
load(file=here::here("../data/BUDS_do02.RData")) # ERP and self-report data
load(file=here("../data/BUDS_behavior.RData")) # ERP behavioral data
load(file=here("../data/BUDS_do03_gaplots.RData")) # Grand average data
spearman_brown <- read.csv(file=here("../tables/spearman_brown.csv")) # Internal consistency table
```

```{r Functions}
# Make my own apa_printlm function that does not include t stats
add_equals2 <- function(p_value) {
  for (p in p_value) {
    if (p < 0.001) {
      return("< 0.001")
    } else {
      return(paste0("=", format(p_value, digits = 2, nsmall =2)))
    }
  }
}

apa_printlm <- function(model) {
  glue_apa_results(broom::tidy(model, conf.int = TRUE)
    , est_glue = "$\\beta=<<estimate>>$, 95% CI [<<conf.low>>,<<conf.high>>]"
    , stat_glue = "*p*<<add_equals2(p.value)>>"
    , term_names = sanitize_terms(make.names(names(coef(model))))
)
}

# from https://www.r-bloggers.com/2020/07/create-a-publication-ready-correlation-matrix-with-significance-levels-in-r/

correlation_matrix <- function(df,
           type = "pearson",
           digits = 3,
           decimal.mark = ".",
           use = "all",
           show_significance = TRUE,
           replace_diagonal = FALSE,
           replacement = ""){
  
  # check arguments
  stopifnot({
  is.numeric(digits)
  digits >= 0
  use %in% c("all", "upper", "lower")
  is.logical(replace_diagonal)
  is.logical(show_significance)
  is.character(replacement)
  })
  # we need the Hmisc package for this
  require(Hmisc)
  
  # retain only numeric and boolean columns
  isNumericOrBoolean = vapply(df, function(x) is.numeric(x) | is.logical(x), logical(1))
  if (sum(!isNumericOrBoolean) > 0) {
  cat('Dropping non-numeric/-boolean column(s):', paste(names(isNumericOrBoolean)[!isNumericOrBoolean], collapse = ', '), '\n\n')
  }
  df = df[isNumericOrBoolean]
  
  # transform input data frame to matrix
  x <- as.matrix(df)
  
  # run correlation analysis using Hmisc package
  correlation_matrix <- Hmisc::rcorr(x, type = )
  R <- correlation_matrix$r # Matrix of correlation coeficients
  p <- correlation_matrix$P # Matrix of p-value
  
  # transform correlations to specific character format
  Rformatted = formatC(R, format = 'f', digits = digits, decimal.mark = decimal.mark)
  
  # if there are any negative numbers, we want to put a space before the positives to align all
  if (sum(R < 0) > 0) {
  Rformatted = ifelse(R > 0, paste0(' ', Rformatted), Rformatted)
  }
  
  # add significance levels if desired
  if (show_significance) {
  # define notions for significance levels; spacing is important.
  stars <- ifelse(is.na(p), " ", ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "*  ", " "))))
  Rformatted = paste0(Rformatted, stars)
  }
  # build a new matrix that includes the formatted correlations and their significance stars
  Rnew <- matrix(Rformatted, ncol = ncol(x))
  rownames(Rnew) <- colnames(x)
  colnames(Rnew) <- paste(colnames(x), "", sep =" ")
  
  # replace undesired values
  if (use == 'upper') {
  Rnew[lower.tri(Rnew, diag = replace_diagonal)] <- replacement
  } else if (use == 'lower') {
  Rnew[upper.tri(Rnew, diag = replace_diagonal)] <- replacement
  } else if (replace_diagonal) {
  diag(Rnew) <- replacement
  }
  
  return(Rnew)
}

lmer_adi_interaction_table <- function(data) {
  new_model <- data.frame(model = c("Both","Acc","Rej"),
          beta = NA, 
          p = NA)
new_model$beta <- c(broom.mixed::tidy(lmer(formula = ERP ~ Feedback*Voting*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = data))[8,4], broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Acc")))[4,4],
        broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Rej")))[4,4])

new_model$p <- c(broom.mixed::tidy(lmer(formula = ERP ~ Feedback*Voting*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = data))[8,8], broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Acc")))[4,8],
        broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Rej")))[4,8])
new_model
}

plot_stats <- function(model, var) {
  temp_stats <- tidy(model) %>% 
  dplyr::filter(term==var) %>%
  dplyr::select(estimate,p.value) %>%
  round(., 3)
  paste0("b = ", temp_stats[1], ", p = ", temp_stats[2])
}

make_long_format <- function(data, site_variable) {
  data %>%
    pivot_longer(cols=c("Acc_Acc","Rej_Acc","Acc_Rej","Rej_Rej"), names_to=c("Voting","Feedback"), names_sep="_", values_to="ERP")
}
```

Low socioeconomic status (SES) in youth is a robust correlate of psychopathology [@mclaughlinSocioeconomicStatusAdolescent2012; @peverillSocioeconomicStatusChild2021] and longitudinal predictor of psychopathology and general health problems into adulthood [@ferraroChildhoodDisadvantageHealth2016; @santiagoSocioeconomicStatusNeighborhood2011]. However, the mechanisms linking SES to psychopathology remain unknown. This study examines whether one potential mechanism---anomalous processing of feedback from others---interacts with SES to influence individual mental health.

Compared to higher SES youth, lower SES youth experience greater prejudice, discrimination, and stigma from others [@cozzarelliAttitudesPoorAttributions2001; @mouraStigmatizationPovertyBasis2019] and numerous theories [@crickReviewReformulationSocial1994; @simonsRelationalSchemasHostile2012] have argued that this may lead to difficulty being open, trusting, and intimate with others [@rokachChapter11Implications2023; @nesdalePeerRejectionChildhood2013]. These experiences may affect the way youth process feedback from others [@simonsRelationalSchemasHostile2012; @simonsLearningBeBad2011], such as through 1) heightened sensitivity to negative feedback (rejection), and/or 2) blunted sensitivity to positive feedback (acceptance). These sensitivities can have short-term benefits such as leading the individual to safely remove themselves from hostile environments [@allenSocialRiskHypothesis2003; @gilbertEvolutionDepressionIssues2006]; however, over time it can lead to pervasive social withdrawal and mental health problems [@ikeSocialWithdrawalInitial].

Indeed, brain studies find that heightened neural rejection sensitivity and blunted neural acceptance sensitivity are tied to internalizing disorders in youth, including depression [@eisenbergerFMRIStudyCytokineinduced2009; @groschwitzDifferentialNeuralProcessing2016; @jankowskiFeelingLeftOut2018; @kumarIncreasedNeuralResponse2017] and socially relevant anxiety [e.g., behavioral inhibition, social anxiety disorder, @beerAnxiouslyElaboratingSocial2016; @guyerLastingAssociationsEarlychildhood2014; @rappaportBrainResponsesSocial2020]. Neural sensitivity to acceptance and rejection can be measured in the lab using event-related potentials (ERPs)---fluctuations in electroencephalography (EEG) signals that are time-locked to accepting and rejecting feedback. Unlike other neural measures like fMRI, ERPs have high temporal resolution (on the order of milliseconds) making them ideal for detecting separate neuropsychological responses to peer feedback. For example, the reward positivity (RewP)---a positive inflection in EEG signal that occurs around 150-250ms post feedback [@proudfitRewardPositivityBasic2015]---likely reflects the rewarding aspects of acceptance in peer feedback [@funkhouserSocialFeedbackValence2020; @ethridgeNeuralResponsesSocial2017]. Additionally, the P300---a positive inflection occurring around 300ms post feedback---likely reflects the salient aspects of acceptance and rejection feedback [@funkhouserSocialFeedbackValence2020; @peggTimeCourseReactivity2022]. The RewP and P300 can therefore be used to index individual differences in brain responses to acceptance and rejection. This contrasts with other ERP components (e.g., N1) which, although elicited by peer feedback, seem to index non-emotional attentional processes [@babinskiSensitivityPeerFeedback2018; @peggTimeCourseReactivity2022]. The N100, then, can be used to test whether internalizing disorders are linked with broad individual differences in affective (RewP, P300) and non-affective processes (N100), or more specifically linked to differences in reward and salience processes.

## Current Study

Despite prior studies showing links between SES and psychopathology, and brain responses to peer feedback and psychopathology, only one study found a link between SES and brain responses to peer feedback [@rappaportBehavioralPsychiatricCorrelates2024a]. This finding was, however, unexpected; SES was included as a covariate and happened to be significantly related to blunted brain responses to peer acceptance. Furthermore, it used a simpler measure of SES that only considers income relative to family size. The current study aims to fill this gap by using an objective, comprehensive measure of SES [area deprivation index [ADI], @kindMakingNeighborhoodDisadvantageMetrics2018; @kindNeighborhoodSocioeconomicDisadvantage2014; @knightonIntroductionAreaDeprivation2016] derived from census data.

The first aim of the study tests whether low SES relates to aberrant brain responses to different kinds of peer feedback -- specifically an, a) more blunted sensitivity to acceptance in the RewP or P300, and/or b) heightened salience of rejection in the P300.

The second aim of the study tests whether SES moderates the relationship between brain responses to peer feedback and negative affect assessed via ecological momentary assessment (EMA). Unlike traditional self-report assessments, EMA provides ecologically valid indicators of affect outside of the lab, as youth go about their daily lives. Furthermore, as EMA collects multiple samples of affect per participant, it yields more accurate measures of trait-like affect than single snapshot assessments and is less susceptible to biases associated with retrospective recall [@moskowitzEcologicalMomentaryAssessment2006; @solhanClinicalAssessmentAffective2009]. Critically, showing that SES moderates the relationship between brain responses to peer feedback and negative affect would support heightened neural rejection sensitivity and/or blunted acceptance sensitivity as potential clinical targets for prevention/intervention. For example, targeted interventions aimed at reducing rejection sensitivity could reduce low SES youths' risk for later life psychopathology.

The third aim explores whether a particular experience of those with low SES---perceived discrimination---is also related to aberrant brain responses. SES is a broad construct and perceived discrimination is a more specific experience of those with low SES, either directly due to their economic standing or other conflated factors[^1] [@cozzarelliAttitudesPoorAttributions2001; @mouraStigmatizationPovertyBasis2019; @williamsRaceSocioeconomicStatus1999]. Moreover, adolescents who experience discrimination may have a particular sensitivity to peer feedback and subsequent risk for psychopathology, although this question has not tested in the literature.

[^1]: Due to sociological factors including systemic oppression of racial minorities, racial minority youth tend to be poorer and more discriminated against than racial majority youth [@drakeRacialDivideAmerican2009; @thompsonAccountingRacialWealth2019].

# Methods and Materials

## Participants

Participant data (N=) was acquired from a larger, ongoing project examining social processing deficits in adolescent depression. Adolescents, ages 13-18-years-old, were recruited from the community (via ads on public transportation, Facebook, and craigslist) and mental health clinics in New York, NY and Chicago, IL. All study procedures were carried out in accordance with the Declaration of Helsinki and approved by the New York State Psychiatric (NYSPI, primary) Institutional Review Board (IRB) and the Northwestern University IRB. See supplement for further information regarding participants, including inclusion and exclusion criteria. Table 1 summarizes the participant demographic and clinical characteristics.

## Procedure

### Social feedback EEG task

Brain responses to social feedback were measured using the Chatroom Task [@guyerAmygdalaVentrolateralPrefrontal2008; @guyerProbingNeuralCorrelates2009] which was completed over two visits. On the first visit, participants were told that they were participating in a multi-site study on adolescent interactions online. Participants created profiles including their likes/dislikes and were told that other participants would review their profile and indicate interest (acceptance) or not (rejection) in chatting with them. Next, participants viewed photographs of 100 same-sex peers and selected 50 that they were 'interested' (high value) and 50 that they were 'not interested' (low value) in chatting with online following the second visit. On the second visit (\~1 week later), participants were presented with the "results" showing whether each of the 100 peers were interested in chatting with them or not, while EEG data was recorded. Each of the 100 trials consisted of a (a) photograph of the peer and a reminder of participants' prior choice (i.e., 'You were [not] interested'), (b) fixation cross for a jittered inter-stimulus interval, and (c) green check or red 'X', indicating whether the peer was 'Interested' or 'Not Interested,' respectively, (i.e., accepting and rejecting feedback; Figure 1A). After each trial, participants rated their emotional response on a sliding scale from 0-100 from 'very bad' to 'very good.' Participants received 50 acceptance and 50 rejection trials --- split by participant interest in the peer (e.g., 25 trials when participants were interested and accepted). Trials were pseudo-randomized with no more than three sequential acceptances/rejections. After completing the task, participants' belief in the task was assessed. Finally, participants were debriefed on the deception.

Importantly, the structure of the task results in four within-subject conditions: 1) acceptance from high-value peers (i.e., peers that participants were interested in talking to), 2) rejection from high-value peers, 3) acceptance from low-value peers (i.e., peers that participants were not interested in talking to), and 4) rejection from low-value peers.

### EEG recording and processing

Continuous EEG data were recorded during the Chatroom task using the 32-channel ActiCHamp from Brain Products (Brain Products, Munich, Germany), digitized at a 500 Hz sampling rate, and referenced online to FCz. Vertical and horizontal EOG data were recorded, and electrode impedances were maintained below 20 KΩ. EEG data were processed offline using EEGLAB version 2022.1 [@delormeEEGLABOpenSource2004] and ERPLAB version 9.00 [@lopez-calderonERPLABOpensourceToolbox2014] toolboxes in MATLAB version r2022b. Independent component analysis (ICA) and automated identification (ICLabel version 1.4) was used to identify and correct for ocular artifacts prior to artifact rejection. Data were re-referenced offline using an average mastoid reference. A 60Hz notch filter and a second-order digital Butterworth filter with a bandpass from 0.1--30Hz were applied. Trials were epoched from -200--2000ms and baseline-adjusted by subtracting the average amplitude for 200ms prior to the stimulus onset (-200--0ms).

Stimulus-locked ERPs were averaged separately for each combination of peer value (high, low) and feedback type (acceptance, rejection). Grand averages were inspected to determine time windows to be extracted (see Figure 1B). Time windows were chosen based on those windows which showed substantial difference between condition, and/or were consistent with prior literature [@donaldsonTemporalDynamicsReversal2016; @funkhouserSocialFeedbackValence2020; @peggTimeCourseReactivity2022]. For the N100, RewP, and P300, time windows of 50-150ms, 150-275ms, and 275-425ms were used, respectively. We also examined effects for the N100 (50-150ms) to test for specific effects outside of the main ERPs of interest (RewP and P300). For the RewP, mean amplitude of the difference between acceptance and rejection was maximal at Cz. Topographic maps of the difference between conditions did not show a clear maximal electrode in the time windows capturing the N100 and P300 (see Supplement). Therefore, maximal electrodes for those two components were based on prior literature, Fz and Pz, respectively.

```{r}
segments_df <- read.csv(here::here("../data/eeg_processing/SegmentCount/summary_erp_bin_RewP.csv")) %>%
  rename_with(~ paste0(., "_seg")) %>%
  mutate(ID = subject_seg) %>%
  select(-subjCount_seg, -subject_seg)

too_few_trials <- function(data, acceptance_trials, rejection_trials) {
  x <- full_join(segments_df,data,by="ID") %>%
    filter(Acc_Acc_seg < acceptance_trials | Acc_Rej_seg < rejection_trials)
  length(x$ID)
}

# sum(complete.cases(df_50150_fz$Acc_Acc) & complete.cases(df_50150_fz$Acc_Rej))
# sum(complete.cases(df_150275_cz$Acc_Acc) & complete.cases(df_150275_cz$Acc_Rej))
# sum(complete.cases(df_275425_pz$Acc_Acc) & complete.cases(df_275425_pz$Acc_Rej))
# 
# too_few_trials(df_50150_fz, 0, 0)
# too_few_trials(df_150275_cz, 13, 11)
# too_few_trials(df_275425_pz, 15, 13)
```

172 participants completed the task. Dependability analyses were used to determine the minimum number of clean trials needed to achieve at least 0.70 dependability for the RewP and P300 (the N1 did not achieve 0.70 at any number of trials, see Dependability in Results below). `r n2w(length(dplyr::filter(segments_df, Acc_Acc_seg < 13 | Acc_Rej_seg < 11)$ID),cap=TRUE)` subjects were excluded for having too few clean trials for the RewP and `r length(dplyr::filter(segments_df, Acc_Acc_seg < 15 | Acc_Rej_seg < 13)$ID)` for the P300 following artifact rejection (at least 13 high-value acceptance and 11 high-value rejection trials for the RewP, and at least 15 high-value acceptance and 13 high-value rejection trials for the P300). This resulted in a sample of N=`r sum(complete.cases(df_50150_fz$Acc_All),na.rm=T)` with usable N100 data, N=`r sum(complete.cases(df_150275_cz$Acc_All),na.rm=T)` with usable RewP data, and N= `r sum(complete.cases(df_275425_pz$Acc_All),na.rm=T)` with usable P300 data.

### Ecological momentary assessment (EMA)

```{r}
subjects_with_less_than_3_responses <- read.csv(file=here::here("../data/number_with_less_than_3_EMA_responses.csv"))
```

Ecological momentary assessment data was collected using the Effortless Assessment of Risk States (EARS) app [@lindEffortlessAssessmentRisk2018; @lindReintroducingEffortlessAssessment2023] for seven days after consenting into the study. Participants received three notifications each day (between 6:30am-8:30am, 3:00pm-5:00pm, and 7:00-10:00pm) to rate their current mood. They rated how happy, excited, supported, angry, anxious, sad, and rejected they felt, on scales from 0 (*not at all*)-100 (*extremely*). The first three were averaged into a positive affect composite, and the latter four in a negative affect composite, and list-wise deletion was used (e.g., if "sad" was skipped, their negative affect composite score was missing for that time point). Participants were compensated $1 for every completed set of questions for a maximum of \$3 per day and \$21 total. `r n2w(length(subjects_with_less_than_3_responses$subject_id), cap=TRUE)` participants were excluded for having made too few EMA responses (\<3).

## Measures

### SES: Area Deprivation Index (ADI)

The area deprivation index [2021 version 4.0.1, @kindMakingNeighborhoodDisadvantageMetrics2018; @universityofwisconsinschoolofmedicineandpublichealthAreaDeprivationIndex2023] is a composite measure based on 17 dimensions of socioeconomic disadvantage of an individual's neighborhood including education, employment, housing quality, and poverty-related factors, all measured via the American Community Survey. Neighborhoods are determined based on block groups and are assigned a percentile from 1 to 100, where a higher percentile indicates greater levels of neighborhood disadvantage. In cases when ADI values were missing for subjects (e.g., suppression due to a high group quarter population), it was estimated using the ADI of the nearest block group with available data (often \<1 mile from the original address). In cases when youth were living on college campuses, they provided their most recent non-college address; however, for four participants these addresses were outside of the USA or could not be obtained, and thus their college address was used. Of note, ADI percentile was reverse scored so that higher scores represented greater SES).

### Discrimination distress: Adolescent Discrimination Distress Index (ADDI)

Discrimination-related distress was measured using the Adolescent Discrimination Distress Index [ADDI, @fisherDiscriminationDistressAdolescence2000]. The ADDI is a 15-item self-report measure that assesses the distress experienced in response to perceived racial-ethnic discrimination across institutional, educational, and peer contexts. Each item includes a statement outlining a common example of discrimination (i.e. "You were called racially insulting names"). If a participant endorsed that they experienced a given type of discrimination, they then rated how much the experience upset them on a five-point Likert scale from "not at all" to "extremely". In the current study, total scores were used, where higher scores indicated greater discrimination-related distress across contexts. Given the format of ADDI, which requires participants to endorse whether an experience occurred in order to report its severity, Cronbach's alpha could not be measured. However, studies support its strong psychometric properties [@fisherDiscriminationDistressAdolescence2000].

### Covariates

#### Depression and anxiety symptoms: Inventory of depression and anxiety symptoms (IDAS-II)

```{r}
idas_dep <- formatC(psych::alpha(df_275425_pz[,c("idas_1_i","idas_2_i","idas_5_i","idas_6_i","idas_8_i","idas_9_i","idas_11_i","idas_13_i","idas_21_i","idas_26_i","idas_30_i","idas_31_i","idas_40_i","idas_48_i","idas_51_i","idas_52_i","idas_57_i","idas_61_i")])$total$std.alpha,format="f",2)
idas_anx <- formatC(psych::alpha(df_275425_pz[,c("idas_7_i","idas_16_i","idas_32_i","idas_39_i","idas_45_i","idas_49_i","idas_56_i","idas_58_i","idas_15_i","idas_18_i","idas_20_i","idas_41_i","idas_47_i","idas_99_i")])$total$std.alpha,format="f",2)
```

The expanded Inventory of Depression and Anxiety Symptoms [IDAS-II, @watsonDevelopmentValidationNew2012] is a 99-item, self-report instrument that measures the severity of depression, anxiety, and bipolar disorder symptoms over the past two weeks. Items are scored on a 5-point scale (1=not at all; 5=extremely). For the present study, 52-items were selected to assess current depression and anxiety symptoms. The depression and anxiety (a combination of the panic and social anxiety subscales) both demonstrated excellent internal consistency (Cronbach's alpha = `r idas_dep`, `r idas_anx`, respectively).

#### Stressful life events and severity of stressful life events: Stress and adversity inventory (STRAIN)

The Stress and Adversity Inventory for Adolescents [STRAIN, @slavichStressAdversityInventory2019] was administered to measure participants' exposure to acute and lifetime stressors. This interview assesses exposures to 75 different stressors across 12 primary life domains (i.e. Housing, Education, Work, Treatment/Health, Marital/Partner, Reproduction, Financial, Legal/Crime, Other Relationships, Parent/Guardian, Death, Life-Threatening Situations) and five social-psychological characteristics (i.e. Interpersonal Loss, Physical Danger, Humiliation, Entrapment, Role Change/Disruption). If a participant endorsed a stressor, they then rated its severity, frequency, timing, and duration. Based on these answers, the STRAIN produces a summary score reflecting participants' total lifetime stressor count and severity for all the acute life events and chronic difficulties experienced, with higher scores indicating more frequent stress exposure. Prior studies support the psychometric properties of the STRAIN, including excellent test-retest reliability [*r* = 0.90---0.95, @cazassaStressAdversityInventory2020; @slavichAssessingLifetimeStress2018]. Given the format of the STRAIN, which requires participants to endorse whether a stressor occurred in order to report its severity, Cronbach's alpha could not be measured. Although the STRAIN and other commonly used measures of stress life events account for some stressful life experiences, recent work suggests that they do not directly measure discrimination-related stressors [@bernardMakingCACECulturallyInformed2021]. This makes the STRAIN a useful measure of stressors separate from the ADDI.

## Data analysis

### Behavioral ratings

Omnibus ANOVAs tested whether in-task behavioral ratings varied as a function of Peer value (high, low) and Feedback type (acceptance and rejection). Post-hoc paired samples t-tests compared levels of Peer value and Feedback type. Multiple regression models (covarying for site, age, and sex-assigned-at-birth) tested whether behavioral ratings were associated with SES.

### ERP task

Omnibus MLMs tested whether mean ERP amplitude varied as a function of Peer value (high, low) and Feedback type (acceptance and rejection).

### Multilevel multiple regression models

#### SES related to ERP residualized scores

For aim 1, we tested whether SES was associated with residualized scores to acceptance and rejection for each component (N1~resid~, RewP~resid~, P300~resid~).

#### SES moderating association between ERP and EMA measures of affect

For aim 2, multilevel multiple regression models (MLMs) tested whether SES moderated associations between ERP amplitudes and EMA ratings of negative/positive affect. These models included random intercept effects of subject and study site. In some models, the random effect of site accounted for so little variance, that the model was singular (i.e., variance of the random effect was essentially zero, likely due to the fact that there were only two sites); in these cases, site was instead included as a fixed effect (i.e., covariate). Given a positive skew and large number of zeros in the measure of negative affect, negative affect was cube-root transformed and zero-inflated Gaussian multilevel models were used. All predictors were included in both the conditional and zero-inflation portions of the model. Similar models were used to assess whether SES moderated associations between in-task behavioral ratings and negative affect.

Visual diagnostic checks for model assumptions were conducted to assure that models were accurately specified (e.g., posterior predictive checks, homogeneity of variance, normality of residuals, colinearity, and normality of random effects).

We used an identical approach to test whether SES moderated associations between mean in-task emotional response rating and negative affect.

# Results

## Behavioral ratings to peer feedback

### In-task emotional response ratings

```{r}
df_BUDS_rating_it_pt <- df_BUDS_rating_it_pt %>%
mutate(site = case_when(ID < 9000 ~ "Columbia",
                          ID > 8999 ~ "Northwestern"))

df_BUDS_rating_it_pt2 <- df_BUDS_rating_it_pt %>%
    dplyr::group_by(ID, Condition) %>%
    dplyr::summarise(rating=mean(rating)) %>%
    dplyr::ungroup() %>%
    pivot_wider(names_from = Condition, values_from = rating, id_cols = ID) %>%
  filter(complete.cases(Acc_Acc)) %>%
  mutate(beh_AA_AR_z = scale(stdres(lm(Acc_Acc ~ Acc_Rej, .)), center=T, scale=T),
         beh_AR_AA_z = scale(stdres(lm(Acc_Rej ~ Acc_Acc, .)), center=T, scale=T),
         beh_RA_RR_z = scale(stdres(lm(Rej_Acc ~ Rej_Rej, .)), center=T, scale=T),
         beh_AA_RA_z = scale(stdres(lm(Acc_Acc ~ Rej_Acc, .)), center=T, scale=T)) %>%
  select(ID, starts_with("beh_"))

df_BUDS_rating_it_pt_demo <- df_BUDS_rating_it_pt2 %>%
  left_join(df_50150_fz, by="ID")

df_BUDS_rating_it_pt_ema <- df_BUDS_rating_it_pt2 %>%
    full_join(df_50150_fz_ema, by="ID") %>%
    mutate(na_cubert = na^(1/3))

ratings_model <- lm(aov(rating ~ site + Feedback*Voting + Error(ID/(Feedback*Voting)), df_BUDS_rating_it_pt)) # wrapping with lm() to make it work with apa_print

ratings_ses_model_AA_AR <- lm(beh_AA_AR_z ~ ADI_NATRANK_z + site + Age_c + demo_child_sex, df_BUDS_rating_it_pt_demo)
ratings_ses_model_AR_AA <- lm(beh_AR_AA_z ~ ADI_NATRANK_z + site + Age_c + demo_child_sex, df_BUDS_rating_it_pt_demo)

model_behavioral_rating_ses_ema_na_ar <- glmmTMB(na_cubert ~ ADI_NATRANK_z*beh_AA_AR_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
                zi = ~ .,
  data = df_BUDS_rating_it_pt_ema,
  family=gaussian, REML=TRUE)
model_behavioral_rating_ses_ema_na_ar_p <- tidy(model_behavioral_rating_ses_ema_na_ar) %>% filter(effect=="fixed",component=="cond",term=="ADI_NATRANK_z:beh_AA_AR_z") %>% select(p.value)

model_behavioral_rating_ses_ema_na_ra <- glmmTMB(na_cubert ~ ADI_NATRANK_z*beh_AR_AA_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
                zi = ~ .,
  data = df_BUDS_rating_it_pt_ema,
  family=gaussian, REML=TRUE)
model_behavioral_rating_ses_ema_na_ra_p <- tidy(model_behavioral_rating_ses_ema_na_ra) %>% filter(effect=="fixed",component=="cond",term=="ADI_NATRANK_z:beh_AR_AA_z") %>% select(p.value)
```

Omnibus MLMs showed a significant Peer value x Feedback type interaction (`r apa_print(ratings_model, est_name="\\beta")$full_result$FeedbackReject_VotingLike`, see Figure 1C), such that participants rated acceptance from high-value peers (i.e., peers that they were interested in) as feeling significantly better than rejection from high-value peers (`r apa_print(t.test(rating ~ Feedback, filter(df_BUDS_rating_it_pt, Voting=="Like"), paired=TRUE))$full_result`). However, participants rated feeling worse in response to acceptance than rejection from low-value peers (`r apa_print(t.test(rating ~ Feedback, filter(df_BUDS_rating_it_pt, Voting=="Dislike"), paired=TRUE))$full_result`).[^2]

[^2]: This somewhat surprising/counter intuitive finding is discussed further in the Supplement.

Residualized scores assessing ratings to acceptance relative to ratings to rejection were not significantly associated with SES (`r apa_printlm(ratings_ses_model_AA_AR)$full_result$ADI_NATRANK_z`), nor were ratings to rejection relative to ratings to acceptance (`r apa_printlm(ratings_ses_model_AR_AA)$full_result$ADI_NATRANK_z`). SES also did not moderate the association between emotional ratings to feedback and EMA negative affect (Rating to acceptance~resid~: *p*=`r round(model_behavioral_rating_ses_ema_na_ar_p$p.value,2)`, Rating to rejection~resid~: *p*=`r round(model_behavioral_rating_ses_ema_na_ra_p$p.value,2)`).

### Post-task ratings

```{r}
df_BUDS_rating_deception <- df_150275_cz %>%
  select(ID,Acc_All,Acc_Acc,Acc_Rej) %>%
  full_join(df_BUDS_rating_it_pt, by="ID") %>%
  filter(complete.cases(Acc_All)) %>%
  group_by(ID) %>%
  filter(row_number() == 1)

post_task_table <- st(dplyr::select(df_BUDS_rating_it_pt, SP_debriefing_interested:SP_debriefing_nervous,SP_debriefing_socialmediause),
        out="return")[,-c(5:8)] %>%
  mutate(Measure=c("Interested","Happy","Upset","Angry","Nervous","Social Media Use")) %>%
  dplyr::select(-Variable, -N) %>%
  dplyr::select(Measure, everything())
```

Only `r round(table(df_BUDS_rating_deception$SP_debriefing_deceived)[2]/sum(table(df_BUDS_rating_deception$SP_debriefing_deceived))*100,2)`% stated that they did not believe that they would be chatting with one of the peers from the task (N= `r sum(is.na(df_BUDS_rating_deception$SP_debriefing_deceived))` missing debriefing data). Given the potential for deception to affect results, we present additional analyses covarying for this in the Supplement.

## Brain responses to peer feedback

### Task effects: Feedback x Value interaction

```{r}
erp_to_long <- function(data) {
  data %>%
  pivot_longer(cols=c("Acc_Acc","Acc_Rej","Rej_Acc","Rej_Rej"), names_sep = "_", names_to = c("Voting","Feedback"), values_to = "ERP")
}

df_50150_fz_long <- erp_to_long(df_50150_fz)
df_150275_cz_long <- erp_to_long(df_150275_cz)
df_275425_pz_long <- erp_to_long(df_275425_pz)

n1_fv_mlm <- lmer(formula = ERP ~ Feedback*Voting + site + (1 | ID), REML=TRUE, data = df_50150_fz_long)
rewp_fv_mlm <- lmer(formula = ERP ~ Feedback*Voting + site + (1 | ID), REML=TRUE, data = df_150275_cz_long)
p300_fv_mlm <- lmer(formula = ERP ~ Feedback*Voting + site + (1 | ID), REML=TRUE, data = df_275425_pz_long)
```

Omnibus MLMs showed that Peer value interacted with Feedback type to predict ERP mean amplitude for the N100 (`r apa_print(n1_fv_mlm, est_name="\\beta")$full_result$FeedbackRej_VotingRej`), RewP (`r apa_print(rewp_fv_mlm, est_name="\\beta")$full_result$FeedbackRej_VotingRej`) and P300 (`r apa_print(p300_fv_mlm, est_name="\\beta")$full_result$FeedbackRej_VotingRej`). Follow-up analyses showed that the N100 (`r apa_print(t.test(df_50150_fz$Rej_Acc, df_50150_fz$Rej_Rej, paired=TRUE))$full_result`), RewP (`r apa_print(t.test(df_150275_cz$Rej_Acc, df_150275_cz$Rej_Rej, paired=TRUE))$full_result`), and P300 (`r apa_print(t.test(df_275425_pz$Rej_Acc, df_275425_pz$Rej_Rej, paired=TRUE))$full_result`) differentiated between acceptance and rejection for low-value peers. Only the RewP differentiated between acceptance and rejection for high-value peers (`r apa_print(t.test(df_150275_cz$Acc_Acc, df_150275_cz$Acc_Rej, paired=TRUE))$full_result`), but not N100 (`r apa_print(t.test(df_50150_fz$Acc_Acc, df_50150_fz$Acc_Rej, paired=TRUE))$full_result`), nor P300 (`r apa_print(t.test(df_275425_pz$Acc_Acc, df_275425_pz$Acc_Rej, paired=TRUE))$full_result`).

### Internal consistency

The RewP and P300 demonstrated acceptable levels of internal consistency across peer-value (high, low) and feedback conditions (acceptance, rejection), with split-half reliability (*r*) \> `r min(spearman_brown[2:3,3:6])`, with particularly high reliability for the high-value peers conditions (acceptance and rejection *r* = `r spearman_brown[2:3,3]` and `r spearman_brown[2:3,4]`). The N100 did not achieve acceptable internal consistency (*r*=`r min(spearman_brown[1,3:6])`-`r max(spearman_brown[1,3:6])`). Split-half reliability was considerably lower for the residualized scores, but remained comparable to other studies (RewP~resid~ *r*\>`r min(spearman_brown[2,7:8])`, P300~resid~ *r*\>`r min(spearman_brown[3,7:8])`) [@rappaportBehavioralPsychiatricCorrelates2024a; @ethridgePsychometricPropertiesNeural2018; @levinsonReliabilityElectrocorticalResponse2017]. See Supplement for full results.

### Dependability

In dependability analyses, the RewP and P300 achieved acceptable dependability ($\ge$ 0.70) with as few as 12-13 and 13-15 trials, respectively, depending on the peer-value and feedback condition. When using all available trials, up to 25 trials per condition, all ERPs achieved good dependability ($\ge$ 0.80; see Supplement). The N100 did not achieve acceptable dependability with any number of trials.

### SES

#### SES associations with N1~resid~, RewP~resid~, and P300~resid~

```{r set-model-predictors}
ses_lm <- function(data, y) {
  y <- enquo(y)

  model_formula <- formula(paste0(quo_name(y), "~ ADI_NATRANK_z + site + Age_c + demo_child_sex + StressCT + StressTH + IDAS_depression + IDAS_anxiety"))
  lm(model_formula, data = data)
}
```

```{r}
n1_aaar_model <- ses_lm(df_50150_fz,AA_AR_z)
n1_araa_model <- ses_lm(df_50150_fz,AR_AA_z)
n1_rarr_model <- ses_lm(df_50150_fz,RA_RR_z)
n1_rrra_model <- ses_lm(df_50150_fz,RR_RA_z)

n1_low_value_ses_pvalues <- c(as.numeric(apa_print(n1_rarr_model)$table$p.value[2]),as.numeric(apa_print(n1_rrra_model)$table$p.value[2]),
  as.numeric(apa_print(n1_rarr_model)$table$p.value[2]),as.numeric(apa_print(n1_rrra_model)$table$p.value[2]))
```

```{r}
rewp_aaar_model <- ses_lm(df_150275_cz,AA_AR_z)
rewp_araa_model <- ses_lm(df_150275_cz,AR_AA_z)
rewp_rarr_model <- ses_lm(df_150275_cz,RA_RR_z)
rewp_rrra_model <- ses_lm(df_150275_cz,RR_RA_z)

rewp_low_value_ses_pvalues <- c(as.numeric(apa_print(rewp_rarr_model)$table$p.value[2]),as.numeric(apa_print(rewp_rrra_model)$table$p.value[2]),
  as.numeric(apa_print(rewp_rarr_model)$table$p.value[2]),as.numeric(apa_print(rewp_rrra_model)$table$p.value[2]))
```

```{r}
p300_aaar_model <- ses_lm(df_275425_pz,AA_AR_z)
p300_araa_model <- ses_lm(df_275425_pz,AR_AA_z)
p300_rarr_model <- ses_lm(df_275425_pz,RA_RR_z)
p300_rrra_model <- ses_lm(df_275425_pz,RR_RA_z)

p300_low_value_ses_pvalues <- c(as.numeric(apa_print(p300_rarr_model)$table$p.value[2]),as.numeric(apa_print(p300_rrra_model)$table$p.value[2]),
  as.numeric(apa_print(p300_rarr_model)$table$p.value[2]),as.numeric(apa_print(p300_rrra_model)$table$p.value[2]))
```

We found support for aim 1: SES was significantly related to brain responses to different kinds of peer feedback (see Figure 2). Specifically, lower SES was significantly related to a more blunted RewP~resid~ and P300~resid~ to acceptance from high-value peers (i.e., peers the participant was interested in). These findings remained significant over-and-above site, demographic factors (e.g., age, sex assigned at birth), lifetime stressors (total stressful life events, severity of stressful life events), and self-reported psychopathology (self-reported depression, self-reported anxiety). SES was not related to RewP~resid~ and P300~resid~ to rejection (`r apa_printlm(rewp_araa_model)$full_result$ADI_NATRANK_z`; `r apa_printlm(p300_araa_model)$full_result$ADI_NATRANK_z`, respectively). Additionally, SES was not related to RewP~resid~ or P300~resid~ to acceptance or rejection from *low-value* peers (i.e., peers the participant was not interested in, $p \ge$ `r round(min(rewp_low_value_ses_pvalues,p300_low_value_ses_pvalues),2)`). Results are consistent when also covarying for self-reported deception (see Supplement).

#### SES moderates association between RewP~resid~/P300~resid~ and negative affect

##### Negative affect

```{r}
model_150275_ema_na <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
                zi = ~ .,
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

model_150275_ema_na_ar <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
                zi = ~ .,
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

model_275425_ema_na <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
                                   zi = ~ .,
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

model_275425_ema_na_ar <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
                                   zi = ~ .,
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

# Positive affect
model_150275_ema_pa <- glmmTMB(pa ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

model_150275_ema_pa_ar <- glmmTMB(pa ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

model_275425_ema_pa <- glmmTMB(pa ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

model_275425_ema_pa_ar <- glmmTMB(pa ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)
```

```{r}
rewp_na_stat <- c(tidy(model_150275_ema_na) %>% 
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_150275_ema_na)) %>% 
                    rownames_to_column("row_name") %>% 
                    filter(row_name == "cond.ADI_NATRANK_z:AA_AR_z") %>% 
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>% 
                       select(lower,upper))

rewp_na_ar_stat <- c(tidy(model_150275_ema_na_ar) %>% 
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AR_AA_z"),
                  as.data.frame(confint(model_150275_ema_na_ar)) %>% 
                    rownames_to_column("row_name") %>% 
                    filter(row_name == "cond.ADI_NATRANK_z:AR_AA_z") %>% 
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>% 
                       select(lower,upper))

p300_na_stat <- c(tidy(model_275425_ema_na) %>%
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_275425_ema_na)) %>%
                    rownames_to_column("row_name") %>%
                    filter(row_name == "cond.ADI_NATRANK_z:AA_AR_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>%
                       select(lower,upper))

p300_na_ar_stat <- c(tidy(model_275425_ema_na_ar) %>% 
                       filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AR_AA_z"),
                     as.data.frame(confint(model_275425_ema_na_ar)) %>% 
                       rownames_to_column("row_name") %>% 
                       filter(row_name == "cond.ADI_NATRANK_z:AR_AA_z") %>% 
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>% 
                       select(lower,upper))

rewp_pa_stat <- c(tidy(model_150275_ema_pa) %>% 
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_150275_ema_pa)) %>% 
                    rownames_to_column("row_name") %>% 
                    filter(row_name == "ADI_NATRANK_z:AA_AR_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>% 
                       select(lower,upper))

rewp_pa_ar_stat <- c(tidy(model_150275_ema_pa_ar) %>% 
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AR_AA_z"),
                  as.data.frame(confint(model_150275_ema_pa)) %>% 
                    rownames_to_column("row_name") %>% 
                    filter(row_name == "ADI_NATRANK_z:AR_AA_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>% 
                       select(lower,upper))

p300_pa_stat <- c(tidy(model_275425_ema_pa) %>%
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_275425_ema_pa)) %>%
                    rownames_to_column("row_name") %>%
                    filter(row_name == "ADI_NATRANK_z:AA_AR_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>%
                       select(lower,upper))

p300_pa_ar_stat <- c(tidy(model_275425_ema_pa_ar) %>%
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AR_AA_z"),
                  as.data.frame(confint(model_275425_ema_pa)) %>%
                    rownames_to_column("row_name") %>%
                    filter(row_name == "ADI_NATRANK_z:AR_AA_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>%
                       select(lower,upper))
```

We also found support for aim 2: SES significantly moderated the relationship between EMA-assessed negative affect and RewP~resid~ to acceptance ($\beta$=`r rewp_na_stat$estimate`, 95% CI=[`r paste0(rewp_na_stat$lower,", ", rewp_na_stat$upper)`], *p*=`r round(rewp_na_stat$p.value,3)`), but not RewP~resid~ to rejection ($\beta$=`r round(rewp_na_ar_stat$estimate,3)`, *p*=`r round(rewp_na_ar_stat$p.value,3)`). SES also moderated the relationship between negative affect and the P300~resid~ to acceptance ($\beta$=`r p300_na_stat$estimate`, 95% CI=[`r paste0(p300_na_stat$lower,", ",p300_na_stat$upper)`], *p*=`r round(p300_na_stat$p.value,3)`) and the P300~resid~ to rejection ($\beta$=`r p300_na_ar_stat$estimate`, 95% CI=[`r paste0(p300_na_ar_stat$lower,", ",p300_na_ar_stat$upper)`], *p*=`r round(p300_na_ar_stat$p.value,3)`); see Figure 3). SES continued to moderate the relationship between negative affect and the P300~resid~ to rejection even when covarying for EMA-assessed positive affect as a fixed effect covariate[^3], as well as when covarying for deception (see Supplement).

[^3]: Models covarying for EMA reported positive affect did not converge for models testing SES moderating relationship between negative affect and RewP\~resid\~ or P300\~resid\~ to acceptance

```{r}
## REWP
######## ACC > REJ ######## 
mean_ses <- mean(df_150275_cz_ema$ADI_NATRANK_z, na.rm=TRUE)
sd_ses <- sd(df_150275_cz_ema$ADI_NATRANK_z, na.rm=TRUE)
SES_list <- list(ADI_NATRANK_z=round(c(mean_ses + sd_ses,mean_ses - sd_ses),2)) 

m_rewp_acc <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
        zi = ~ .,
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

m_rewp_acc_ss <- emtrends(m_rewp_acc, pairwise ~ADI_NATRANK_z, var="AA_AR_z",at=SES_list, adjust="none")|> test()

## P300
mean_ses <- mean(df_275425_pz_ema$ADI_NATRANK_z, na.rm=TRUE)
sd_ses <- sd(df_275425_pz_ema$ADI_NATRANK_z, na.rm=TRUE)
SES_list <- list(ADI_NATRANK_z=round(c(mean_ses + sd_ses,mean_ses - sd_ses),2)) 
######## ACC > REJ ######## 
m_p300_acc <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
        zi = ~ .,
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

m_p300_acc_ss <- emtrends(m_p300_acc, pairwise ~ADI_NATRANK_z, var="AA_AR_z",at=SES_list, adjust="none")|> test()
######## REJ > ACC ######## 
m_p300_rej <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + (1 | site) + (1 | ID),
        zi = ~ .,
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

m_p300_rej_ss <- emtrends(m_p300_rej, pairwise ~ADI_NATRANK_z, var="AR_AA_z",at=SES_list, adjust="none")|> test()
```

Follow-up simple slope analyses showed that while no simple slopes were significant for the SES x RewP~resid~ interaction ($p\ge$ `r round(min(m_rewp_acc_ss$emtrends[,6]),2)`), there were significant simple slopes for the SES x P300~resid~ such that lower SES was associated with a more negative relationship between P300~resid~ to *acceptance* and subsequent negative affect (slope = `r round(m_p300_acc_ss$emtrends[2,2],2)`, *p*=`r round(m_p300_acc_ss$emtrends[2,6],2)`), and positive relationship between P300~resid~ to *rejection* and subsequent negative affect (slope = `r round(m_p300_rej_ss$emtrends[2,2],2)`, *p*=`r round(m_p300_rej_ss$emtrends[2,6],2)`). That is, individuals with lower SES who had blunted acceptance sensitivity or heightened rejection sensitivity exhibited greater negative affect outside of the lab.

##### Positive affect

SES did not moderate the relationship between positive affect and RewP~resid~ to acceptance ($\beta$=`r rewp_pa_stat$estimate`, 95% CI=[`r paste0(rewp_pa_stat$lower,", ", rewp_pa_stat$upper)`], *p*=`r rewp_pa_stat$p.value`) or rejection ($\beta$=`r rewp_pa_ar_stat$estimate`, 95% CI=[`r paste0(rewp_pa_ar_stat$lower,", ", rewp_pa_ar_stat$upper)`], *p*=`r rewp_pa_ar_stat$p.value`), nor between positive affect and P300~resid~ to acceptance ($\beta$=`r p300_pa_stat$estimate`, 95% CI=[`r paste0(p300_pa_stat$lower,", ", p300_pa_stat$upper)`], *p*=`r p300_pa_stat$p.value`) or rejection ($\beta$=`r p300_pa_ar_stat$estimate`, 95% CI=[`r paste0(p300_pa_ar_stat$lower,", ", p300_pa_ar_stat$upper)`], *p*=`r p300_pa_ar_stat$p.value`).

### Discrimination distress
```{r, eval=FALSE}
paste0("N = ",sum(complete.cases(df_150275_cz$AA_AR) & complete.cases(df_150275_cz$addi_total_z)))
paste0("r RewP and ADDI: ", round(corr.test(df_150275_cz$AA_AR, df_150275_cz$addi_total_z)$r,2))
paste0("r P300 and ADDI: ", round(corr.test(df_275425_pz$AA_AR, df_275425_pz$addi_total_z)$r,2))
paste0("r P300 (AR_AA) and ADDI: ", round(corr.test(df_275425_pz$AR_AA, df_275425_pz$addi_total_z)$r,2))
paste0("r SES and ADDI: ", round(corr.test(df_150275_cz$ADI_NATRANK, df_150275_cz$addi_total)$r,2))
```

```{r}
# RewP
model_150275_addi <- lm(AA_AR_z ~ addi_total_z + Age_c + demo_child_sex + site, df_150275_cz)
model_150275_addi_ar <- lm(AR_AA_z ~ addi_total_z + Age_c + demo_child_sex + site, df_150275_cz)
# P300
model_275425_addi <- lm(AA_AR_z ~ addi_total_z + Age_c + demo_child_sex + site, data = df_275425_pz)
model_275425_addi_ar <- lm(AR_AA_z ~ addi_total_z + Age_c + demo_child_sex + site, data = df_275425_pz)

model_275425_addi_ar_adi <- lm(AR_AA_z ~ addi_total_z + ADI_NATRANK_z + Age_c + demo_child_sex + site, data = df_275425_pz)

df_150275_cz_complete <- filter(df_150275_cz, complete.cases(AA_AR))
n_reported_disc <- paste0(sum(df_150275_cz_complete$addi_total>0, na.rm=TRUE),", ",round(sum(df_150275_cz_complete$addi_total>0, na.rm=TRUE)/sum(complete.cases(df_150275_cz_complete$addi_total))*100,2),"%")

hist(df_275425_pz$addi_total)
```

Greater self-reported discrimination distress was significantly related to heightened P300~resid~ (`r  apa_print(model_275425_addi_ar)$full_result$addi_total_z`) to rejection, even over-and-above SES (`r  apa_print(model_275425_addi_ar_adi)$full_result$addi_total_z`). However, these results are considered preliminary since only a sub-sample of participants reported having experienced *any* form of discrimination (`r n_reported_disc`).

<!--# Greater self-reported discrimination distress was related to a more blunted RewP~resid~ (`r apa_print(model_150275_addi)$full_result$addi_total_z`) and P300~resid~ (`r apa_print(model_275425_addi)$full_result$addi_total_z`) to acceptance and more heightened response RewP~resid~ (`r apa_print(model_150275_addi_ar)$full_result$addi_total_z`) and P300~resid~ to rejection (`r apa_print(model_275425_addi_ar)$full_result$addi_total_z`). However, these results are considered preliminary since only `r sum(df_150275_cz_complete$addi_total>0, na.rm=TRUE)` (`r round(sum(df_150275_cz_complete$addi_total>0, na.rm=TRUE)/sum(complete.cases(df_150275_cz_complete$addi_total))*100,2)`%) participants reported having experienced *any* form of discrimination. -->

### Race/Ethnicity

```{r}
model_150275_hisp <- lm(AA_AR_z ~ demo_child_hispanic + site, df_150275_cz)
model_150275_hisp_ar <- lm(AR_AA_z ~ demo_child_hispanic + site, df_150275_cz)
model_275425_hisp <- lm(AA_AR_z ~ demo_child_hispanic + site, df_275425_pz)
model_275425_hisp_ar <- lm(AR_AA_z ~ demo_child_hispanic + site, df_275425_pz)

df_150275_cz_race <- df_150275_cz %>%
  mutate(demo_child_race = as.factor(demo_child_race)) %>%
  # filter(demo_child_race == "White" | demo_child_race=="Black or African American" |
  #        demo_child_race == "Asian" | demo_child_race=="More than one race") %>%
  mutate(demo_child_race = relevel(demo_child_race, ref = "White"),
         demo_child_minority = case_match(demo_child_race, "White" ~ "no",
                                          NA ~ NA,
                                          .default = "yes"))
df_275425_pz_race <- df_275425_pz %>%
  mutate(demo_child_race = as.factor(demo_child_race)) %>%
  # filter(demo_child_race == "White" | demo_child_race=="Black or African American" |
  #        demo_child_race == "Asian" | demo_child_race=="More than one race") %>%
  mutate(demo_child_race = relevel(demo_child_race, ref = "White"),
         demo_child_minority = case_match(demo_child_race, "White" ~ "no",
                                          NA ~ NA,
                                          .default = "yes"))

model_150275_race <- lm(AA_AR_z ~ demo_child_minority + + site, df_150275_cz_race)
model_150275_race_ar <- lm(AR_AA_z ~ demo_child_minority + site, df_150275_cz_race)
model_275425_race <- lm(AA_AR_z ~ demo_child_minority + site, df_275425_pz_race)
model_275425_race_ar <- lm(AR_AA_z ~ demo_child_minority + site, df_275425_pz_race)
```

Finally, we examined whether RewP~resid~ or P300~resid~ differed by Hispanic ethnicity or participant reported race, given that racial/ethnic minority youth are at greater likelihood of being discriminated against. We did not find significant differences for Hispanic ethnicity in the RewP~resid~ to acceptance or rejection (*p*=`r round(tidy(model_150275_hisp)[2,5],2)`, `r round(tidy(model_150275_hisp_ar)[2,5],2)`, respectively), nor P300~resid~ (*p*=`r round(tidy(model_275425_hisp)[2,5],2)`, `r round(tidy(model_275425_hisp_ar)[2,5],2)`). We also did not find significant differences between white and non-white participants for the RewP~resid~ to acceptance or rejection (*p*=`r round(tidy(model_150275_race)[2,5],2)`, `r round(tidy(model_150275_race_ar)[2,5],2)`, respectively), nor P300~resid~ (*p*=`r round(tidy(model_275425_race)[2,5],2)`, `r round(tidy(model_275425_race_ar)[2,5],2)`, respectively).

```{r, eval=FALSE}
performance::check_model(model_275425_ema_na_ar, data=df_275425_pz_ema, plot = TRUE)
```

# Discussion

The current study found important links between SES and neural response to social feedback---SES was (a) related to aberrant responses to peer acceptance and rejection, and (b) moderated the association between neural response to feedback and negative affect assessed outside of the lab. Follow-up analyses indicated that lower SES adolescents who had a more blunted neural response to acceptance (as indicated by a smaller P300~resid~) and greater neural response to rejection (as indicated by a larger P300~resid~) reported greater daily experiences of negative affect. We also found some preliminary evidence that experiences with discrimination may be one of the factors implicated in the association between SES and blunted neural responses to acceptance. These findings build on prior literature, with clear implications for basic and adolescent psychiatry.

## Linking SES to psychopathology

The present study provides novel evidence of one potential mechanism through which youth SES may lead to heightened risk for internalizing disorders in adolescence. Because this data cannot determine the causal direction between SES, brain responses to peer feedback, and daily negative affect, we do not know whether changes in brain responsivity lead to daily negative affect or vice versa. One possibility is that low SES environments lead to greater negative affect [@galloUnderstandingAssociationSocioeconomic2003], which in turn leads to blunted sensitivity to acceptance and heightened sensitivity to rejection. Another possibility is that growing up in a low SES environment may make youth less sensitive to positive social feedback and more sensitive to negative social feedback, relative to their higher SES peers. Such interpersonal sensitivities may then lead to greater daily negative affect, and chronic experiences of negative affect may in turn lead to depression. Prior data most support this pathway. Numerous studies [@eisenbergerFMRIStudyCytokineinduced2009; @groschwitzDifferentialNeuralProcessing2016; @jankowskiFeelingLeftOut2018; @kumarIncreasedNeuralResponse2017; @beerAnxiouslyElaboratingSocial2016; @guyerLastingAssociationsEarlychildhood2014; @rappaportBrainResponsesSocial2020] have shown that depressed youth exhibit a blunted response to social acceptance, and anxious youth a heightened response to social rejection (though see @guNeuralCorrelatesNegative2020 and @harrewijnBehavioralEEGResponses2018 for examples of social anxiety being related to *enhanced* response to social acceptance too). Longitudinal studies have also shown that low SES prospectively predicts changes in the way youth report on their relationships [@simonsRelationalSchemasHostile2012; @simonsLearningBeBad2011], and that clinical levels of social anhedonia and rejection sensitivity cross-sectionally and prospectively predict greater depression [@llerenaSocialAnhedoniaAffiliation2012; @aydukRejectionSensitivityDepressive2001; @gaoAssociationsRejectionSensitivity2017]. Thus, these findings together with prior research suggest one intriguing explanation for how youth SES may lead to adolescent depression.

To our knowledge, only one other study examined the association between SES neural sensitivity to feedback, and the present study replicates and builds on this prior study [@rappaportBehavioralPsychiatricCorrelates2024a]. While both studies were comparable sample sizes, age ranges, and oversampled individuals with depression, the prior study used a 1) different measure of SES (income-to-needs) and 2) different social feedback task than the current study. ADI is a more reliable and objective measure of SES than income-to-needs as it is composite measure rather than a single measure and is derived from the American Community Survey rather than self-report. , Additionally, the present study collected a large, clinically-enriched sample from two different, diverse metro areas, and measured experience with negative affect via daily ecological momentary assessments over a week as opposed to self-report at a single timepoint. Finally, the current study collected a measure of self-reported experiences of discrimination, and accounted for common clinical covariates (e.g., depression and anxiety symptoms, stressful life events). This allowed us to test whether the association between SES and brain responses to feedback explains psychopathology risk.

## Linking SES to depression risk via discrimination experiences

The present study also explored whether a key aspect of SES---discrimination---relates to neural response to social feedback. The findings support and add to theories that discrimination leads to heightened threat-sensitive responses to peer rejection [@faniAssociationRacialDiscrimination2021; @chanStatusBasedRejectionSensitivity2008]. We show that discrimination may be tied to a heightened sensitivity to rejection. Future research could further test whether discrimination experiences moderate or are mediated by associations between neural sensitivity to acceptance/rejection and risk for psychopathology, as recent research suggests [@dyarMediatingRolesRejection2018; @feinsteinRelationshipExperiencesDiscrimination2012].

It is important to note that low SES has multiple components, determinants, and consequences, with discrimination representing just one potential factor putting low SES youth at risk for psychopathology. However, social stressors such as discrimination may be one of the most powerful aspects of low SES linking it to psychopathology. For example, perceived discrimination, as well as several related social factors (e.g., lower perceived social status), are related to a wide range of psychiatric disorders over-and-above other, non-social aspects of SES, such as income, income inequality, and parental education [@gurBurdenEnvironmentalAdversity2019; @mclaughlinSocioeconomicStatusAdolescent2012; @assariSubjectiveSocioeconomicStatus2018; @chouPerceptionRacialDiscrimination2012; @xieAssociationsRacialSocioeconomic2020]. Moreover, other experiences with rejection---such as experiences being bullied---have been tied to blunted responses to peer acceptance [@rappaportPeerVictimizationDysfunctional2019]. Hostile and/or rejecting experiences early in life may lead to children becoming sensitive to perceived rejection and skeptical of acceptance, and ultimately at risk for psychopathology.

Clinically, these findings suggest that prevention and intervention focused on increasing hedonic responses to acceptance and reducing rejection sensitivity in safe, non-threatening situations may alleviate psychopathology. For example, short-term solutions may include helping youth heal from racial trauma [e.g., @metzgerHealingInterpersonalRacial2021], or interventions aimed at cultivating positive peer interactions [@pollakSystematicReviewIntervention2023]. Longer-term solutions may involve systemic interventions focused on reducing instances of discrimination [@bartlettGettingRootProblem2022].

## Strengths and Limitations

The current study has additional, noteworthy strengths to those identified above. First, these findings extend previous research detailing how the brain responds to social feedback. At a group level, we show that an fMRI task of neural responses to social feedback---the Chatroom task [@pagliaccioNeuralSensitivityPeer2022; @guyerAmygdalaVentrolateralPrefrontal2008]---yields the expected ERP components: RewP and P300. We also show these components have acceptable psychometrics (split-half reliability/internal consistency and dependability). Finding that the RewP and P300 occur across this and other social feedback tasks [@weinbergNeuralResponsesSocial2021; @kujawaSocialProcessingEarly2017; @rappaportBehavioralPsychiatricCorrelates2024a; @distefanoComparisonElectrocorticalResponse2018] speaks to the generalizable role of these components in responding to rewarding and salient feedback, respectively. Additionally, we demonstrate functional specificity: that the task elicits specific processes and not brain-wide differences--ERPs to acceptance and rejection within the N100 time window did not significantly differ from each other and exhibited low internal consistency and dependability. Second, the emotional ratings assessed during the social feedback task verified that participants felt 'better' when accepted and 'worse' when rejected by peers that they were interested in chatting with (i.e., high-value peers).

## Limitations

The current study must also be considered in light of its limitations. First, although the area deprivation index provides a rich measure of the neighborhood youth are currently living, it does not capture other aspects of adolescents' environment such as where they spend significant time (e.g., school, after school activities). Second, we did not assess how long youth had been living at this address; it is possible that some youth had recently moved to their address (although due to low upward mobility in the USA [@chettyEconomicMobility2018] it is unlikely SES dramatically changed). Third, we did not examine how the perceived race or ethnicity of the peers giving feedback impact brain responses. Half of the feedback came from white peers, while the other half came from peers perceived to be non-white. Thus, we were unfortunately under-powered to test whether peer perceived race or ethnicity interacted with neural response to feedback. Future versions of this and other social feedback tasks with more trials from peers of different racial and ethnic backgrounds will be key to more rigorously testing for racial or ethnic group differences. Fourth, one could question the validity of labeling the ERP components we identified as a RewP and P300. These components have, however, been identified in many other studies of social feedback within similar time windows and scalp topographies [@weinbergNeuralResponsesSocial2021; @kujawaSocialProcessingEarly2017; @rappaportBehavioralPsychiatricCorrelates2024a; @distefanoComparisonElectrocorticalResponse2018], and like other studies, we found that ERPs to acceptance were significantly greater than to rejection in the RewP time window, but did not differ within the P300 time window [@rappaportBehavioralPsychiatricCorrelates2024a; @peggTimeCourseReactivity2022]. Fifth, we were unfortunately under-powered to test whether discrimination moderated relationships between EMA-assessed affect and brain responses to feedback. As noted above, this is an important question for future studies.

In conclusion, this study has clear implications for basic and clinical research on the role of SES in psychopathology. Recent studies are beginning to elucidate the role and consequences of SES [@correaEthnicDifferencesBehavioral2022] on not only symptoms of psychopathology, but their underlying neurobiological mechanisms as well [e.g., @sheridanChapter13Neurodevelopmental2020; @palacios-barriosPovertySelfregulationConnecting2019; @barchEarlyChildhoodSocioeconomic2022]. At the very least, accounting for SES in analyses will help assure that findings examining neural mechanisms of psychopathology are not influenced by a large potential third-variable. More broadly, studying consequences of SES can potentially influence public policies aimed at lifting at-risk children out of poverty.

\newpage

# Figures

Figure 1. A) Example of trial from chatroom task. B) Grand average ERP for acceptance and rejection feedback from high-value peers. Colored sections of the graph represent time windows where ERP components were extracted at Cz electrode: N1 = purple, RewP = orange, P300 = blue. C) Mean in-task, post-feedback ratings across all participants by Feedback (acceptance, rejection) and Value (high, low).

Figure 2. A) Relationship between SES and brain responses to acceptance (relative to rejection) for both the RewP and P300 ERP components. B) Interactions for which SES significantly moderated associated between brain responses to acceptance/rejection and negative affect. A: no simple slopes significant. B: Simple slope significant for SES -1 standard deviation below the mean.

# References

::: {#refs custom-style="Bibliography"}
:::
