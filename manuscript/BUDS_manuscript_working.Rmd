---
title     : "Socioeconomic status and adolescent brain responses to peer feedback: Testing the impact on negative affect"
shorttitle    : "SES & brain responses to peer feedback"

author: 
  - name    : "Brent I. Rappaport"
    affiliation : "1"
    corresponding : yes  # Define only one corresponding author
    address   : "680 N. Lakeshore Drive, Suite 1520, Chicago, IL 60611"
    email   : "brent.rappaport@northwestern.edu"
    role:   # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Formal analysis"
      - "Methodology"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name    : "James E. Glazer"
    affiliation : "1"
    role:
      - "Methodology"
      - "Writing - Review & Editing"
  - name    : "Allison M. Letkiewicz"
    affiliation : "1"
    role:
      - "Writing - Review & Editing"
  - name    : "Lilian Y. Li"
    affiliation : "1"
    role:
      - "Methodology"
      - "Writing - Review & Editing"
  - name    : "Madeline M. McGregor"
    affiliation : "1"
    role:
      - "Writing - Review & Editing"
  - name    : "Aishwarya Sritharan"
    affiliation : "2"
    role:
    - "Data curation"  
    - "Project administration"
  - name    : "Lili A. Massac"
    affiliation : "2"
    role:
    - "Writing - Review & Editing"
  - name    : "Katherine Durham"
    affiliation : "2"
    role:
    - "Project administration"
  - name          : "Randy Auerbach"
    affiliation   : "2"
    role:
      - "Conceptualization"
      - "Fundind acquisition"
      - "Investigation"
      - "Methodology"
      - "Resources"
      - "Supervision"
      - "Writing - Review & Editing"
  - name          : "Stewart A. Shankman"
    affiliation   : "1"
    role:
      - "Conceptualization"
      - "Fundind acquisition"
      - "Investigation"
      - "Methodology"
      - "Resources"
      - "Supervision"
      - "Writing - Review & Editing"

affiliation:
  - id    : "1"
    institution : "Department of Psychiatry, Feinberg School of Medicine, Northwestern University"
  - id    : "2"
    institution : "Department of Psychiatry, Columbia University"

abstract: |
  *Background*: Lower socioeconomic status (SES) is a risk factor for psychopathology in youth. One neural mechanism that may link SES to psychopathology risk is aberrant brain responding to peer acceptance and rejection. This study will test whether SES (operationalized as neighborhood area deprivation) is 1) related to brain responses to peer feedback, and 2) moderates the relationship between brain responses to peer feedback and affect measured through experience sampling methods. *Methods*: Adolescent participants (N=172, ages 13-19) were administered an event-related potential (ERP) task while receiving accepting or rejecting feedback from peers to probe reward and salience sensitive brain responses (i.e., reward positivity [RewP] and P3, respectively). Additionally, they completed a week of ecological momentary assessment (EMA) reporting on their positive and negative affect. *Results:* Lower SES was related to blunted responses to acceptance (RewP to acceptance residualized for response to rejection), interestingly, lower SES moderated relationships between brain responses to peer acceptance (RewP, P3) and rejection (P3) and negative affect. Specifically, lower SES was related to a more negative relationship between brain response to *acceptance* (P3) and negative affect, and a more positive relationship between brain responses to *rejection* (P3) and EMA reported negative affect.  *Conclusions*: SES may be linked to negative affect via blunted sensitivity to acceptance and heightened sensitivity to rejection. These findings suggest that prevention and intervention efforts targeting sensitivity to social feedback may reduce risk for internalizing disorders particularly in low SES youth.
  
keywords    : "social feedback, socioeconomic status, area deprivation, negative affect"

bibliography  : "BUDS.bib"
floatsintext  : yes
linenumbers   : no
draft         : no
mask          : no
figurelist    : no
tablelist     : no
footnotelist  : no
csl     : 'biological-psychiatry.csl'
# csl     : 'apa7.csl'
documentclass   : "apa7"
output        : papaja::apa6_word
  
editor_options: 
  markdown: 
  wrap: sentence
  
header-includes:
  - \usepackage{setspace}
  - \AtBeginEnvironment{tabular}{\singlespacing}
  - \AtBeginEnvironment{lltable}{\singlespacing}
  - \addtolength{\tabcolsep}{6pt}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1.5}}
  
  - \raggedbottom
  # - \usepackage{helvet}
  # - \renewcommand{\familydefault}{\sfdefault}
---

```{r analysis-preferences}
knitr::opts_chunk$set(set.seed(312), warning=FALSE, message=FALSE, include=FALSE, results='hide')
  options(width=80, Ncpus = 6, mc.cores=6, max.print=1000000, scipen = 999) #Set width, multiple cores, and not to use scientific notation
  rm(list=ls())   #Remove everything from environment
  cat("\014")   #Clear Console

  # library(knitr)  #allows rmarkdown files
  library(haven)  #helps import stata
  library(expss)  #labeling variables/values
  library(broom.mixed)  #nice statistical output
  library(here)   #nice file paths
  library(psych)  #used for statistical analyses
  library(Hmisc)
  library(purrr)
  library(haven)  #to import SPSS files
  library(MASS)   #to create residualized scores
# Models
  library(lmerTest)
  library(glmmTMB)
# Plotting
  library(ggplot2)  #creates plots
  library(ggpubr)
  library(ggeffects)
  library(sjPlot)
  library(sjPlot)
  library(marginaleffects)
  library(interactions)
  library(latex2exp)
  library(emmeans) # testing simple slopes

  library(datawizard)
  library(performance)
  library(xfun)
  library(Rmisc)
  library(vtable)
# General tools
  library(tidyverse)  #plotting/cleaning, etc.
  library(scipub) #demo table
  library(r2symbols) # symbols inline text
  library(papaja)
  library(workflowr)  #helps with workflow
  library(dplyr)

here <- here::here
here::i_am("BUDS_manuscript_working.Rmd")

filter <- dplyr::filter

r_refs("BUDS.bib")
```

```{r Load data}
load(file=here::here("../data/BUDS_do02.RData")) # ERP and self-report data
load(file=here("../data/BUDS_behavior.RData")) # ERP behavioral data
load(file=here("../data/BUDS_do03_gaplots.RData")) # Grand average data
spearman_brown <- read.csv(file=here("../tables/spearman_brown.csv")) # Internal consistency table
```

```{r Functions}
# Make my own apa_printlm function that does not include t stats
add_equals2 <- function(p_value) {
  for (p in p_value) {
    if (p < 0.001) {
      return("< 0.001")
    } else {
      return(paste0("=", format(p_value, digits = 2, nsmall =2)))
    }
  }
}

apa_printlm <- function(model) {
  glue_apa_results(broom::tidy(model, conf.int = TRUE)
    , est_glue = "$\\beta=<<estimate>>$, 95% CI [<<conf.low>>,<<conf.high>>]"
    , stat_glue = "*p*<<add_equals2(p.value)>>"
    , term_names = sanitize_terms(make.names(names(coef(model))))
)
}

# from https://www.r-bloggers.com/2020/07/create-a-publication-ready-correlation-matrix-with-significance-levels-in-r/

correlation_matrix <- function(df,
           type = "pearson",
           digits = 3,
           decimal.mark = ".",
           use = "all",
           show_significance = TRUE,
           replace_diagonal = FALSE,
           replacement = ""){
  
  # check arguments
  stopifnot({
  is.numeric(digits)
  digits >= 0
  use %in% c("all", "upper", "lower")
  is.logical(replace_diagonal)
  is.logical(show_significance)
  is.character(replacement)
  })
  # we need the Hmisc package for this
  require(Hmisc)
  
  # retain only numeric and boolean columns
  isNumericOrBoolean = vapply(df, function(x) is.numeric(x) | is.logical(x), logical(1))
  if (sum(!isNumericOrBoolean) > 0) {
  cat('Dropping non-numeric/-boolean column(s):', paste(names(isNumericOrBoolean)[!isNumericOrBoolean], collapse = ', '), '\n\n')
  }
  df = df[isNumericOrBoolean]
  
  # transform input data frame to matrix
  x <- as.matrix(df)
  
  # run correlation analysis using Hmisc package
  correlation_matrix <- Hmisc::rcorr(x, type = )
  R <- correlation_matrix$r # Matrix of correlation coeficients
  p <- correlation_matrix$P # Matrix of p-value
  
  # transform correlations to specific character format
  Rformatted = formatC(R, format = 'f', digits = digits, decimal.mark = decimal.mark)
  
  # if there are any negative numbers, we want to put a space before the positives to align all
  if (sum(R < 0) > 0) {
  Rformatted = ifelse(R > 0, paste0(' ', Rformatted), Rformatted)
  }
  
  # add significance levels if desired
  if (show_significance) {
  # define notions for significance levels; spacing is important.
  stars <- ifelse(is.na(p), " ", ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "*  ", " "))))
  Rformatted = paste0(Rformatted, stars)
  }
  # build a new matrix that includes the formatted correlations and their significance stars
  Rnew <- matrix(Rformatted, ncol = ncol(x))
  rownames(Rnew) <- colnames(x)
  colnames(Rnew) <- paste(colnames(x), "", sep =" ")
  
  # replace undesired values
  if (use == 'upper') {
  Rnew[lower.tri(Rnew, diag = replace_diagonal)] <- replacement
  } else if (use == 'lower') {
  Rnew[upper.tri(Rnew, diag = replace_diagonal)] <- replacement
  } else if (replace_diagonal) {
  diag(Rnew) <- replacement
  }
  
  return(Rnew)
}

lmer_adi_interaction_table <- function(data) {
  new_model <- data.frame(model = c("Both","Acc","Rej"),
          beta = NA, 
          p = NA)
new_model$beta <- c(broom.mixed::tidy(lmer(formula = ERP ~ Feedback*Voting*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = data))[8,4], broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Acc")))[4,4],
        broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Rej")))[4,4])

new_model$p <- c(broom.mixed::tidy(lmer(formula = ERP ~ Feedback*Voting*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = data))[8,8], broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Acc")))[4,8],
        broom.mixed::tidy(lmer(formula = ERP ~ Feedback*ADI_NATRANK_c + (1 | ID), REML=TRUE, data = filter(data, Voting=="Rej")))[4,8])
new_model
}

plot_stats <- function(model, var) {
  temp_stats <- tidy(model) %>% 
  dplyr::filter(term==var) %>%
  dplyr::select(estimate,p.value) %>%
  round(., 3)
  paste0("b = ", temp_stats[1], ", p = ", temp_stats[2])
}

make_long_format <- function(data, site_variable) {
  data %>%
    pivot_longer(cols=c("Acc_Acc","Rej_Acc","Acc_Rej","Rej_Rej"), names_to=c("Voting","Feedback"), names_sep="_", values_to="ERP")
}
```

Low socioeconomic status (SES) in adolescence is a known correlate of psychopathology [@mclaughlinSocioeconomicStatusAdolescent2012; @peverillSocioeconomicStatusChild2021] and longitudinal predictor of psychopathology and general health problems into adulthood [@ferraroChildhoodDisadvantageHealth2016; @santiagoSocioeconomicStatusNeighborhood2011]. However, the mechanisms linking SES to psychopathology remain unknown. This study examines whether one potential mechanism---anomalous processing of feedback from others---interacts with SES to influence individual mental health.

Compared to higher SES youth, lower SES youth experience greater prejudice, discrimination, and stigma from others [@cozzarelliAttitudesPoorAttributions2001; @mouraStigmatizationPovertyBasis2019]; numerous theories [@crickReviewReformulationSocial1994; @simonsRelationalSchemasHostile2012] argue that this leads to difficulty being open, trusting, and intimate with others [@rokachChapter11Implications2023; @nesdalePeerRejectionChildhood2013]. This is because these experiences may affect the way youth process feedback from others [@simonsRelationalSchemasHostile2012; @simonsLearningBeBad2011], such as through 1) heightened sensitivity to negative feedback (rejection), and/or 2) blunted sensitivity to positive feedback (acceptance). These sensitivities can have short-term benefits such as leading the individual to safely remove themselves from hostile environments [@allenSocialRiskHypothesis2003; @gilbertEvolutionDepressionIssues2006]; however, over time it can lead to pervasive social withdrawal and mental health problems [@ikeSocialWithdrawalInitially2020].

Indeed, brain studies find that heightened neural rejection sensitivity and blunted neural acceptance sensitivity are tied to internalizing disorders in youth, including depression [@eisenbergerFMRIStudyCytokineinduced2009; @groschwitzDifferentialNeuralProcessing2016; @jankowskiFeelingLeftOut2018; @kumarIncreasedNeuralResponse2017] and socially relevant anxiety [e.g., behavioral inhibition, social anxiety disorder, @beerAnxiouslyElaboratingSocial2016; @guyerLastingAssociationsEarlychildhood2014; @rappaportBrainResponsesSocial2020]. Neural sensitivity to acceptance and rejection can be measured in the lab using event-related potentials (ERPs)---fluctuations in electroencephalography (EEG) signals that are time-locked to accepting and rejecting feedback. Unlike other neural measures like fMRI, ERPs have high temporal resolution (on the order of milliseconds) making them ideal for detecting separate neuropsychological responses to peer feedback. For example, the reward positivity (RewP)---a positive inflection in EEG signal that occurs around 200ms post feedback [@proudfitRewardPositivityBasic2015]---likely reflects the rewarding aspects of acceptance in peer feedback [@funkhouserSocialFeedbackValence2020; @ethridgeNeuralResponsesSocial2017]. Additionally, the P3---a positive inflection occurring around 300ms post feedback---likely reflects the salient aspects of acceptance and rejection feedback [@funkhouserSocialFeedbackValence2020; @peggTimeCourseReactivity2022]. The RewP and P3 can therefore be used to index individual differences in brain responses to acceptance and rejection. This contrasts with other ERP components (e.g., N1) which, although elicited by peer feedback, seem to index non-emotional attentional processes [@babinskiSensitivityPeerFeedback2018; @peggTimeCourseReactivity2022]. The N100, then, can be used to test whether internalizing disorders are linked with broad individual differences in affective (RewP, P3) and non-affective processes (N100), or more specifically linked to differences in reward and salience processes.

## Current Study

Despite prior studies showing links between SES and psychopathology, and brain responses to peer feedback and psychopathology, only one study found a link between SES and brain responses to peer feedback [@rappaportBehavioralPsychiatricCorrelates2024a]. This finding was, however, unexpected; SES was included as a covariate and happened to be significantly related to blunted brain responses to peer acceptance. Furthermore, it used a simpler measure of SES that only considers income relative to family size. The current study aims to fill this gap by using an objective, comprehensive measure of SES [area deprivation index [ADI], @kindMakingNeighborhooddisadvantageMetrics2018; @kindNeighborhoodSocioeconomicDisadvantage2014; @knightonIntroductionAreaDeprivation2016] derived from census data.

The first aim of the study tests whether low SES relates to aberrant brain responses to different kinds of peer feedback -- specifically an, a) more blunted sensitivity to acceptance in the RewP or P3, and/or b) heightened salience of rejection in the P3.

The second aim of the study tests whether SES moderates the relationship between brain responses to peer feedback and negative affect assessed via ecological momentary assessment (EMA). Unlike traditional self-report assessments, EMA provides ecologically valid indicators of affect outside of the lab, as youth go about their daily lives. Furthermore, as EMA collects multiple samples of affect per participant, it yields more accurate measures of trait-like affect than single snapshot assessments and is less susceptible to biases associated with retrospective recall [@moskowitzEcologicalMomentaryAssessment2006; @solhanClinicalAssessmentAffective2009]. Critically, showing that SES moderates the relationship between brain responses to peer feedback and negative affect would support heightened neural rejection sensitivity and/or blunted acceptance sensitivity as potential clinical targets for prevention/intervention. For example, targeted interventions aimed at reducing rejection sensitivity could reduce low SES youths' risk for later life psychopathology.

# Methods and Materials

## Participants

Participant data (N=172) was acquired from a larger, ongoing project examining social processing deficits in adolescent depression. Adolescents, ages 13-18-years-old, were recruited from the community (via ads on public transportation, Facebook, and craigslist) and mental health clinics in New York, NY and Chicago, IL. All study procedures were carried out in accordance with the Declaration of Helsinki and approved by the New York State Psychiatric (NYSPI, primary) Institutional Review Board (IRB) and the Northwestern University IRB. See supplement for further information regarding participants, including inclusion and exclusion criteria. Table 1 summarizes the participant demographic and clinical characteristics.

## Procedure

**Social feedback EEG task**

Brain responses to social feedback were measured using the Chatroom Task [@guyerAmygdalaVentrolateralPrefrontal2008; @guyerProbingNeuralCorrelates2009] which was completed over two visits. On the first visit, participants were told that they were participating in a multi-site study on adolescent interactions online. Participants created profiles including their likes/dislikes and were told that other participants would review their profile and indicate interest (acceptance) or not (rejection) in chatting with them. Next, participants viewed photographs of 100 same-sex peers and selected 50 that they were 'interested' (high value) and 50 that they were 'not interested' (low value) in chatting with online following the second visit. On the second visit (\~1 week later), participants were presented with the "results" showing whether each of the 100 peers were interested in chatting with them or not, while EEG data was recorded. Each of the 100 trials consisted of a (a) photograph of the peer and a reminder of participants' prior choice (i.e., 'You were [not] interested'), (b) fixation cross for a jittered inter-stimulus interval, and (c) green check or red 'X', indicating whether the peer was 'Interested' or 'Not Interested,' respectively, (i.e., accepting and rejecting feedback; Figure 1A). After each trial, participants rated their emotional response on a sliding scale from 0-100 from 'very bad' to 'very good.' Participants received 50 acceptance and 50 rejection trials --- split by participant interest in the peer (e.g., 25 trials when participants were interested and accepted). Trials were pseudo-randomized with no more than three sequential acceptances/rejections. After completing the task, participants' belief in the task was assessed. Finally, participants were debriefed on the deception.

Importantly, the structure of the task results in four within-subject conditions: 1) acceptance from high-value peers (i.e., peers that participants were interested in talking to), 2) rejection from high-value peers, 3) acceptance from low-value peers (i.e., peers that participants were not interested in talking to), and 4) rejection from low-value peers.

**EEG recording and processing**

Continuous EEG data were recorded during the Chatroom task using the 32-channel ActiCHamp from Brain Products (Brain Products, Munich, Germany), digitized at a 500 Hz sampling rate, and referenced online to FCz. Vertical and horizontal EOG data were recorded, and electrode impedances were maintained below 20 K$\Omega$. EEG data were processed offline using EEGLAB version 2022.1 [@delormeEEGLABOpenSource2004] and ERPLAB version 9.00 [@lopez-calderonERPLABOpensourceToolbox2014] toolboxes in MATLAB version r2022b. Independent component analysis (ICA) and automated identification (ICLabel version 1.4) was used to identify and correct for ocular artifacts prior to artifact rejection. Data were re-referenced offline using an average mastoid reference. A 60Hz notch filter and a second-order digital Butterworth filter with a bandpass from 0.1--30Hz were applied. Trials were epoched from -200--2000ms and baseline-adjusted by subtracting the average amplitude for 200ms prior to the stimulus onset (-200--0ms).

Stimulus-locked ERPs were averaged separately for each combination of peer value (high, low) and feedback type (acceptance, rejection). Grand averages were inspected to determine time windows to be extracted (see Figure 1B). Time windows were chosen based on those windows which showed substantial difference between condition, and/or were consistent with prior literature [@donaldsonTemporalDynamicsReversal2016; @funkhouserSocialFeedbackValence2020; @peggTimeCourseReactivity2022]. For the N100, RewP, and P3, time windows of 50-150ms, 150-275ms, and 275-425ms were used, respectively. We also examined effects for the N100 (50-150ms) to test for specific effects outside of the main ERPs of interest (RewP and P3). For the RewP, mean amplitude of the difference between acceptance and rejection was maximal at Cz. Topographic maps of the difference between conditions did not show a clear maximal electrode in the time windows capturing the N100 and P3 (see Supplement). Therefore, maximal electrodes for those two components were based on prior literature, Fz and Pz, respectively.

```{r}
segments_df <- read.csv(here::here("../data/eeg_processing/SegmentCount/summary_erp_bin_RewP.csv")) %>%
  rename_with(~ paste0(., "_seg")) %>%
  mutate(ID = subject_seg) %>%
  select(-subjCount_seg, -subject_seg)

too_few_trials <- function(data, acceptance_trials, rejection_trials) {
  x <- full_join(segments_df,data,by="ID") %>%
    filter(Acc_Acc_seg < acceptance_trials | Acc_Rej_seg < rejection_trials)
  length(x$ID)
}

# sum(complete.cases(df_50150_fz$Acc_Acc) & complete.cases(df_50150_fz$Acc_Rej))
# sum(complete.cases(df_150275_cz$Acc_Acc) & complete.cases(df_150275_cz$Acc_Rej))
# sum(complete.cases(df_275425_pz$Acc_Acc) & complete.cases(df_275425_pz$Acc_Rej))
# 
# too_few_trials(df_50150_fz, 0, 0)
# too_few_trials(df_150275_cz, 13, 11)
# too_few_trials(df_275425_pz, 15, 13)
```

One hundred seventy-two participants completed the task. Dependability analyses were used to determine the minimum number of clean trials needed to achieve at least 0.70 dependability for the RewP and P3 (the N100 did not achieve 0.70 at any number of trials, see Dependability in Results below). `r n2w(length(dplyr::filter(segments_df, Acc_Acc_seg < 13 | Acc_Rej_seg < 11)$ID),cap=TRUE)` subjects were excluded for having too few clean trials for the RewP and `r length(dplyr::filter(segments_df, Acc_Acc_seg < 15 | Acc_Rej_seg < 13)$ID)` for the P3 following artifact rejection (at least 13 high-value acceptance and 11 high-value rejection trials were needed to dependably measure the RewP, and at least 15 high-value acceptance and 13 high-value rejection trials for the P3). This resulted in a sample of N=`r sum(complete.cases(df_50150_fz$Acc_All),na.rm=T)` with usable N100 data, N=`r sum(complete.cases(df_150275_cz$Acc_All),na.rm=T)` with usable RewP data, and N= `r sum(complete.cases(df_275425_pz$Acc_All),na.rm=T)` with usable P3 data.

**Ecological momentary assessment (EMA)**

```{r}
subjects_with_less_than_3_responses <- read.csv(file=here::here("../data/number_with_less_than_3_EMA_responses.csv"))
```

Ecological momentary assessment data was collected using the Effortless Assessment of Risk States (EARS) app [@lindEffortlessAssessmentRisk2018; @lindReintroducingEffortlessAssessment2023] for seven days after consenting into the study. Participants received three notifications each day (between 6:30am-8:30am, 3:00pm-5:00pm, and 7:00-10:00pm) to rate their current mood. They rated how happy, excited, supported, angry, anxious, sad, and rejected they felt, on scales from 0 (*not at all*)-100 (*extremely*). The first three were averaged into a positive affect composite, and the latter four in a negative affect composite, and list-wise deletion was used (e.g., if "sad" was skipped, their negative affect composite score was missing for that time point). Participants were compensated \$1 for every completed set of questions for a maximum of \$3 per day and \$21 total. `r n2w(length(subjects_with_less_than_3_responses$subject_id), cap=TRUE)` participants were excluded for having made too few EMA responses (\<3).

## Measures

**SES: Area Deprivation Index (ADI)**

The area deprivation index [2021 version 4.0.1, @kindMakingNeighborhooddisadvantageMetrics2018; @universityofwisconsinschoolofmedicineandpublichealthAreaDeprivationIndex2023] is a composite measure based on 17 dimensions of socioeconomic disadvantage of an individual's neighborhood including education, employment, housing quality, and poverty-related factors, all measured via the American Community Survey. Neighborhoods are determined based on block groups and are assigned a percentile from 1 to 100, where a higher percentile indicates greater levels of neighborhood disadvantage. In cases when ADI values were missing for subjects (e.g., suppression due to a high group quarter population), it was estimated using the ADI of the nearest block group with available data (often \<1 mile from the original address). In cases when youth were living on college campuses, they provided their most recent non-college address; however, for four participants these addresses were outside of the USA or could not be obtained, and thus their college address was used. Of note, ADI percentile was reverse scored so that higher scores represented greater SES).

**Covariates**

***Depression and anxiety symptoms: Inventory of depression and anxiety symptoms (IDAS-II)***

```{r}
idas_dep <- formatC(psych::alpha(df_275425_pz[,c("idas_1_i","idas_2_i","idas_5_i","idas_6_i","idas_8_i","idas_9_i","idas_11_i","idas_13_i","idas_21_i","idas_26_i","idas_30_i","idas_31_i","idas_40_i","idas_48_i","idas_51_i","idas_52_i","idas_57_i","idas_61_i")])$total$std.alpha,format="f",2)
idas_anx <- formatC(psych::alpha(df_275425_pz[,c("idas_7_i","idas_16_i","idas_32_i","idas_39_i","idas_45_i","idas_49_i","idas_56_i","idas_58_i","idas_15_i","idas_18_i","idas_20_i","idas_41_i","idas_47_i","idas_99_i")])$total$std.alpha,format="f",2)
```

The expanded Inventory of Depression and Anxiety Symptoms [IDAS-II, @watsonDevelopmentValidationNew2012] is a 99-item, self-report instrument that measures the severity of depression, anxiety, and bipolar disorder symptoms over the past two weeks. Items are scored on a 5-point scale (1=not at all; 5=extremely). For the present study, 52-items were selected to assess current depression and anxiety symptoms. The depression and anxiety (a combination of the panic and social anxiety subscales) both demonstrated excellent internal consistency (Cronbach's $\alpha$ = `r idas_dep`, `r idas_anx`, respectively).

***Stressful life events and severity of stressful life events: Stress and adversity inventory (STRAIN)***

The Stress and Adversity Inventory for Adolescents [STRAIN, @slavichStressAdversityInventory2019] was administered to measure participants' exposure to acute and lifetime stressors. This interview assesses exposures to 75 different stressors across 12 primary life domains (i.e. Housing, Education, Work, Treatment/Health, Marital/Partner, Reproduction, Financial, Legal/Crime, Other Relationships, Parent/Guardian, Death, Life-Threatening Situations) and five social-psychological characteristics (i.e. Interpersonal Loss, Physical Danger, Humiliation, Entrapment, Role Change/Disruption). If a participant endorsed a stressor, they then rated its severity, frequency, timing, and duration. Based on these answers, the STRAIN produces two summary scores reflecting participants' 1) total lifetime stressor count and 2) severity for all the acute life events and chronic difficulties experienced, with higher scores indicating more frequent stress exposure and greater severity. Prior studies support the psychometric properties of the STRAIN, including excellent test-retest reliability [*r* = 0.90-0.95, @cazassaStressAdversityInventory2020; @slavichAssessingLifetimeStress2018]. Given the format of the STRAIN, which requires participants to endorse whether a stressor occurred in order to report its severity, Cronbach's alpha could not be measured.

## Data analysis

**Behavioral ratings**

Omnibus ANOVAs tested whether in-task behavioral ratings varied as a function of Peer value (high, low) and Feedback type (acceptance and rejection). Post-hoc paired samples t-tests compared levels of Peer value and Feedback type. Multiple regression models (covarying for site, age, and sex-assigned-at-birth) tested whether behavioral ratings were associated with SES.

**ERP task**

Omnibus MLMs tested whether mean ERP amplitude varied as a function of Peer value (high, low) and Feedback type (acceptance and rejection).

**Multilevel multiple regression models**

***SES related to ERP residualized scores***

For aim 1, we tested whether SES was associated with residualized scores to acceptance and rejection for each component (N1~resid~, RewP~resid~, P3~resid~).

***SES moderating association between ERP and EMA measures of affect***

For aim 2, multilevel multiple regression models tested whether SES moderated associations between ERP amplitudes and EMA ratings of negative/positive affect. These models included random intercept effects of subject and study site. In some models, the random effect of site accounted for so little variance, that the model was singular (i.e., variance of the random effect was essentially zero, likely because there were only two sites); in these cases, site was instead included as a fixed effect (i.e., covariate). Given a positive skew and large number of zeros in the measure of negative affect, negative affect was cube-root transformed and zero-inflated Gaussian multilevel models were used. All predictors were included in both the conditional and zero-inflation portions of the model. Similar models were used to assess whether SES moderated associations between in-task behavioral ratings and negative affect.

Visual diagnostic checks for model assumptions were conducted to assure that models were accurately specified (e.g., posterior predictive checks, homogeneity of variance, normality of residuals, collinearity, and normality of random effects).

We used an identical approach to test whether SES moderated associations between mean in-task emotional response rating and negative affect.

# Results

## Behavioral ratings to peer feedback

**In-task emotional response ratings**

```{r}
df_BUDS_rating_it_pt <- df_BUDS_rating_it_pt %>%
mutate(site = case_when(ID < 9000 ~ "NYC",
                          ID > 8999 ~ "Chicago"))

df_BUDS_rating_it_pt2 <- df_BUDS_rating_it_pt %>%
    dplyr::group_by(ID, Condition) %>%
    dplyr::summarise(rating=mean(rating)) %>%
    dplyr::ungroup() %>%
    pivot_wider(names_from = Condition, values_from = rating, id_cols = ID) %>%
  filter(complete.cases(Acc_Acc)) %>%
  mutate(beh_AA_AR_z = scale(stdres(lm(Acc_Acc ~ Acc_Rej, .)), center=T, scale=T),
         beh_AR_AA_z = scale(stdres(lm(Acc_Rej ~ Acc_Acc, .)), center=T, scale=T),
         beh_RA_RR_z = scale(stdres(lm(Rej_Acc ~ Rej_Rej, .)), center=T, scale=T),
         beh_AA_RA_z = scale(stdres(lm(Acc_Acc ~ Rej_Acc, .)), center=T, scale=T)) %>%
  select(ID, starts_with("beh_"))

df_BUDS_rating_it_pt_demo <- df_BUDS_rating_it_pt2 %>%
  left_join(df_50150_fz, by="ID")

df_BUDS_rating_it_pt_ema <- df_BUDS_rating_it_pt2 %>%
    full_join(df_50150_fz_ema, by="ID") %>%
    mutate(na_cubert = na^(1/3))

ratings_model <- lm(aov(rating ~ site + Feedback*Voting + Error(ID/(Feedback*Voting)), df_BUDS_rating_it_pt)) # wrapping with lm() to make it work with apa_print

ratings_ses_model_AA_AR <- lm(beh_AA_AR_z ~ ADI_NATRANK_z + site + Age_c + demo_child_sex, df_BUDS_rating_it_pt_demo)
ratings_ses_model_AR_AA <- lm(beh_AR_AA_z ~ ADI_NATRANK_z + site + Age_c + demo_child_sex, df_BUDS_rating_it_pt_demo)

model_behavioral_rating_ses_ema_na_ar <- glmmTMB(na_cubert ~ ADI_NATRANK_z*beh_AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
                zi = ~ .,
  data = df_BUDS_rating_it_pt_ema,
  family=gaussian, REML=TRUE)
model_behavioral_rating_ses_ema_na_ar_p <- tidy(model_behavioral_rating_ses_ema_na_ar) %>% filter(effect=="fixed",component=="cond",term=="ADI_NATRANK_z:beh_AA_AR_z") %>% select(p.value)

model_behavioral_rating_ses_ema_na_ra <- glmmTMB(na_cubert ~ ADI_NATRANK_z*beh_AR_AA_z + Age_c + demo_child_sex + site + (1 | ID),
                zi = ~ .,
  data = df_BUDS_rating_it_pt_ema,
  family=gaussian, REML=TRUE)
model_behavioral_rating_ses_ema_na_ra_p <- tidy(model_behavioral_rating_ses_ema_na_ra) %>% filter(effect=="fixed",component=="cond",term=="ADI_NATRANK_z:beh_AR_AA_z") %>% select(p.value)

model_behavioral_rating_ses_ema_pa_ar <- glmmTMB(pa ~ ADI_NATRANK_z*beh_AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
  data = df_BUDS_rating_it_pt_ema,
  family=gaussian, REML=TRUE)
model_behavioral_rating_ses_ema_pa_ar_p <- tidy(model_behavioral_rating_ses_ema_pa_ar) %>% filter(effect=="fixed",component=="cond",term=="ADI_NATRANK_z:beh_AA_AR_z") %>% select(p.value)

# model_behavioral_rating_ses_ema_pa_ra <- glmmTMB(pa ~ ADI_NATRANK_z*beh_AR_AA_z + Age_c + demo_child_sex + site + (1 | ID),
#   data = df_BUDS_rating_it_pt_ema,
#   family=gaussian, REML=TRUE)
# model_behavioral_rating_ses_ema_pa_ra_p <- tidy(model_behavioral_rating_ses_ema_pa_ra) %>% filter(effect=="fixed",component=="cond",term=="ADI_NATRANK_z:beh_AR_AA_z") %>% select(p.value)
```

Omnibus MLMs showed a significant Peer value x Feedback type interaction (`r apa_print(ratings_model, est_name="\\beta")$full_result$FeedbackReject_VotingLike`, see Figure 1C), such that participants rated acceptance from high-value peers (i.e., peers that they were interested in) as feeling significantly better than rejection from high-value peers (`r apa_print(t.test(rating ~ Feedback, filter(df_BUDS_rating_it_pt, Voting=="Like"), paired=TRUE))$full_result`). However, participants rated feeling worse in response to acceptance than rejection from low-value peers (`r apa_print(t.test(rating ~ Feedback, filter(df_BUDS_rating_it_pt, Voting=="Dislike"), paired=TRUE))$full_result`).[^1]

[^1]: This somewhat surprising/counter intuitive finding is discussed further in the Supplement.

Residualized scores assessing ratings to acceptance relative to ratings to rejection were not significantly associated with SES (`r apa_printlm(ratings_ses_model_AA_AR)$full_result$ADI_NATRANK_z`), nor were ratings to rejection relative to ratings to acceptance (`r apa_printlm(ratings_ses_model_AR_AA)$full_result$ADI_NATRANK_z`). SES also did not moderate the association between emotional ratings to feedback and EMA negative affect (Rating to acceptance~resid~: *p*=`r round(model_behavioral_rating_ses_ema_na_ar_p$p.value,2)`, Rating to rejection~resid~: *p*=`r round(model_behavioral_rating_ses_ema_na_ra_p$p.value,2)`), or EMA positive affect (Rating to rejection~resid~: *p*=`r round(model_behavioral_rating_ses_ema_pa_ra_p$p.value,2)`). However, SES moderated the association between emotional ratings to acceptance feedback and EMA positive affect at trend level (Rating to acceptance~resid~: *p*=`r round(model_behavioral_rating_ses_ema_pa_ar_p$p.value,2)`).

**Belief in deception**

```{r}
df_BUDS_rating_deception <- df_150275_cz %>%
  select(ID,Acc_All,Acc_Acc,Acc_Rej) %>%
  full_join(df_BUDS_rating_it_pt, by="ID") %>%
  filter(complete.cases(Acc_All)) %>%
  group_by(ID) %>%
  filter(row_number() == 1)

post_task_table <- st(dplyr::select(df_BUDS_rating_it_pt, SP_debriefing_interested:SP_debriefing_nervous,SP_debriefing_socialmediause),
        out="return")[,-c(5:8)] %>%
  mutate(Measure=c("Interested","Happy","Upset","Angry","Nervous","Social Media Use")) %>%
  dplyr::select(-Variable, -N) %>%
  dplyr::select(Measure, everything())
```

Only `r round(table(df_BUDS_rating_deception$SP_debriefing_deceived)[2]/sum(table(df_BUDS_rating_deception$SP_debriefing_deceived))*100,2)`% stated that they did not believe that they would be chatting with one of the peers from the task (N= `r sum(is.na(df_BUDS_rating_deception$SP_debriefing_deceived))` missing debriefing data). Given the potential for deception to affect results, we present additional analyses covarying for this in the Supplement.

## Brain responses to peer feedback

**Task effects: Feedback x Value interaction**

```{r}
erp_to_long <- function(data) {
  data %>%
  pivot_longer(cols=c("Acc_Acc","Acc_Rej","Rej_Acc","Rej_Rej"), names_sep = "_", names_to = c("Voting","Feedback"), values_to = "ERP")
}

df_50150_fz_long <- erp_to_long(df_50150_fz)
df_150275_cz_long <- erp_to_long(df_150275_cz)
df_275425_pz_long <- erp_to_long(df_275425_pz)

n1_fv_mlm <- lmer(formula = ERP ~ Feedback*Voting + site + (1 | ID), REML=TRUE, data = df_50150_fz_long)
rewp_fv_mlm <- lmer(formula = ERP ~ Feedback*Voting + site + (1 | ID), REML=TRUE, data = df_150275_cz_long)
p300_fv_mlm <- lmer(formula = ERP ~ Feedback*Voting + site + (1 | ID), REML=TRUE, data = df_275425_pz_long)
```

Omnibus MLMs showed that Peer value interacted with Feedback type to predict ERP mean amplitude for the N100 (`r apa_print(n1_fv_mlm, est_name="\\beta")$full_result$FeedbackRej_VotingRej`), RewP (`r apa_print(rewp_fv_mlm, est_name="\\beta")$full_result$FeedbackRej_VotingRej`) and P3 (`r apa_print(p300_fv_mlm, est_name="\\beta")$full_result$FeedbackRej_VotingRej`). Follow-up analyses showed that the N100 (`r apa_print(t.test(df_50150_fz$Rej_Acc, df_50150_fz$Rej_Rej, paired=TRUE))$full_result`), RewP (`r apa_print(t.test(df_150275_cz$Rej_Acc, df_150275_cz$Rej_Rej, paired=TRUE))$full_result`), and P3 (`r apa_print(t.test(df_275425_pz$Rej_Acc, df_275425_pz$Rej_Rej, paired=TRUE))$full_result`) differentiated between acceptance and rejection for low-value peers. Only the RewP differentiated between acceptance and rejection for high-value peers (`r apa_print(t.test(df_150275_cz$Acc_Acc, df_150275_cz$Acc_Rej, paired=TRUE))$full_result`), but not N100 (`r apa_print(t.test(df_50150_fz$Acc_Acc, df_50150_fz$Acc_Rej, paired=TRUE))$full_result`), nor P3 (`r apa_print(t.test(df_275425_pz$Acc_Acc, df_275425_pz$Acc_Rej, paired=TRUE))$full_result`).

**Internal consistency**

The RewP and P3 demonstrated acceptable levels of internal consistency across peer-value (high, low) and feedback conditions (acceptance, rejection), with split-half reliability (*r*) \> `r min(spearman_brown[2:3,3:6])`, with particularly high reliability for the high-value peers conditions (acceptance *r* = `r spearman_brown[2:3,3]` and rejection *r* = `r spearman_brown[2:3,4]` for RewP and P3, respectively). The N100 did not achieve acceptable internal consistency (*r*=`r min(spearman_brown[1,3:6])`-`r max(spearman_brown[1,3:6])`). Split-half reliability was considerably lower for the residualized scores, but remained comparable to other studies (RewP~resid~ *r*\>`r min(spearman_brown[2,7])`, P3~resid~ *r*\>`r min(spearman_brown[3,7])`) [@rappaportBehavioralPsychiatricCorrelates2024a; @ethridgePsychometricPropertiesNeural2018; @levinsonReliabilityElectrocorticalResponse2017]. See Supplement for full results.

**Dependability**

In dependability analyses, the RewP and P3 achieved acceptable dependability ($\ge$ 0.70) with as few as 12-13 and 13-15 trials, respectively, depending on the peer-value and feedback condition. When using all available trials, up to 25 trials per condition, RewP and P3 achieved good dependability ($\ge$ 0.80; see Supplement). The N100 did not achieve acceptable dependability with any number of trials.

**SES**

***SES associations with N1~resid~, RewP~resid~, and P3~resid~***

```{r set-model-predictors}
ses_lm <- function(data, y) {
  y <- enquo(y)

  model_formula <- formula(paste0(quo_name(y), "~ ADI_NATRANK_z + site + Age_c + demo_child_sex + StressCT + StressTH + IDAS_depression + IDAS_anxiety"))
  lm(model_formula, data = data)
}
```

```{r}
n1_aaar_model <- ses_lm(df_50150_fz,AA_AR_z)
n1_araa_model <- ses_lm(df_50150_fz,AR_AA_z)
n1_rarr_model <- ses_lm(df_50150_fz,RA_RR_z)
n1_rrra_model <- ses_lm(df_50150_fz,RR_RA_z)

n1_low_value_ses_pvalues <- c(as.numeric(apa_print(n1_rarr_model)$table$p.value[2]),as.numeric(apa_print(n1_rrra_model)$table$p.value[2]),
  as.numeric(apa_print(n1_rarr_model)$table$p.value[2]),as.numeric(apa_print(n1_rrra_model)$table$p.value[2]))
```

```{r}
rewp_aaar_model <- ses_lm(df_150275_cz,AA_AR_z)
rewp_araa_model <- ses_lm(df_150275_cz,AR_AA_z)
rewp_rarr_model <- ses_lm(df_150275_cz,RA_RR_z)
rewp_rrra_model <- ses_lm(df_150275_cz,RR_RA_z)

rewp_low_value_ses_pvalues <- c(as.numeric(apa_print(rewp_rarr_model)$table$p.value[2]),as.numeric(apa_print(rewp_rrra_model)$table$p.value[2]),
  as.numeric(apa_print(rewp_rarr_model)$table$p.value[2]),as.numeric(apa_print(rewp_rrra_model)$table$p.value[2]))
```

```{r}
p300_aaar_model <- ses_lm(df_275425_pz,AA_AR_z)
p300_araa_model <- ses_lm(df_275425_pz,AR_AA_z)
p300_rarr_model <- ses_lm(df_275425_pz,RA_RR_z)
p300_rrra_model <- ses_lm(df_275425_pz,RR_RA_z)

p300_low_value_ses_pvalues <- c(as.numeric(apa_print(p300_rarr_model)$table$p.value[2]),as.numeric(apa_print(p300_rrra_model)$table$p.value[2]),
  as.numeric(apa_print(p300_rarr_model)$table$p.value[2]),as.numeric(apa_print(p300_rrra_model)$table$p.value[2]))
```

We found support for aim 1: SES was significantly related to brain responses to different kinds of peer feedback (see Figure 2). Specifically, lower SES was significantly related to a more blunted RewP~resid~ and P3~resid~ to acceptance from high-value peers (i.e., peers the participant was interested in). These findings remained significant over-and-above site, demographic factors (e.g., age, sex assigned at birth), lifetime stressors (total stressful life events, severity of stressful life events), and self-reported psychopathology (self-reported depression, self-reported anxiety). SES was not related to RewP~resid~ nor P3~resid~ to rejection (`r apa_printlm(rewp_araa_model)$full_result$ADI_NATRANK_z`; `r apa_printlm(p300_araa_model)$full_result$ADI_NATRANK_z`, respectively). Additionally, SES was not related to RewP~resid~ or P3~resid~ to acceptance or rejection from *low-value* peers (i.e., peers the participant was not interested in, $p \ge$ `r round(min(rewp_low_value_ses_pvalues,p300_low_value_ses_pvalues),2)`). Results are consistent when also covarying for self-reported deception (see Supplement).

***SES moderates association between RewP~resid~/P3~resid~ and affect***

```{r}
model_150275_ema_na <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
                zi = ~ .,
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

# model_150275_ema_na_ar <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + site + (1 | ID),
#                 zi = ~ .,
#   data = df_150275_cz_ema,
#   family=gaussian, REML=TRUE)

model_275425_ema_na <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
                                   zi = ~ .,
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

# model_275425_ema_na_ar <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + site + (1 | ID),
#                                    zi = ~ .,
#   data = df_275425_pz_ema,
#   family=gaussian, REML=TRUE)

# Positive affect
model_150275_ema_pa <- glmmTMB(pa ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

# model_150275_ema_pa_ar <- glmmTMB(pa ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + site + (1 | ID),
#   data = df_150275_cz_ema,
#   family=gaussian, REML=TRUE)

model_275425_ema_pa <- glmmTMB(pa ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

# model_275425_ema_pa_ar <- glmmTMB(pa ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + site + (1 | ID),
#   data = df_275425_pz_ema,
#   family=gaussian, REML=TRUE)
```

```{r}
rewp_na_stat <- c(tidy(model_150275_ema_na) %>% 
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_150275_ema_na)) %>% 
                    rownames_to_column("row_name") %>% 
                    filter(row_name == "cond.ADI_NATRANK_z:AA_AR_z") %>% 
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>% 
                       select(lower,upper))

p300_na_stat <- c(tidy(model_275425_ema_na) %>%
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_275425_ema_na)) %>%
                    rownames_to_column("row_name") %>%
                    filter(row_name == "cond.ADI_NATRANK_z:AA_AR_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>%
                       select(lower,upper))

rewp_pa_stat <- c(tidy(model_150275_ema_pa) %>% 
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_150275_ema_pa)) %>% 
                    rownames_to_column("row_name") %>% 
                    filter(row_name == "ADI_NATRANK_z:AA_AR_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>% 
                       select(lower,upper))

p300_pa_stat <- c(tidy(model_275425_ema_pa) %>%
                    filter(effect == "fixed", component == "cond", term == "ADI_NATRANK_z:AA_AR_z"),
                  as.data.frame(confint(model_275425_ema_pa)) %>%
                    rownames_to_column("row_name") %>%
                    filter(row_name == "ADI_NATRANK_z:AA_AR_z") %>%
                       mutate(lower = round(`2.5 %`,2), upper=round(`97.5 %`,2)) %>%
                       select(lower,upper))
```

We also found support for aim 2: SES significantly moderated the relationship between EMA-assessed negative affect and RewP~resid~ to acceptance ($\beta$=`r rewp_na_stat$estimate`, 95% CI=[`r paste0(rewp_na_stat$lower,", ", rewp_na_stat$upper)`], *p*=`r rewp_na_stat$p.value`), but not RewP~resid~ to rejection ($\beta$=`r rewp_na_ar_stat$estimate`, *p*=`r rewp_na_ar_stat$p.value`). SES also moderated the relationship between negative affect and the P3~resid~ to acceptance ($\beta$=`r p300_na_stat$estimate`, 95% CI=[`r paste0(p300_na_stat$lower,", ",p300_na_stat$upper)`], *p*=`r p300_na_stat$p.value`) and the P3~resid~ to rejection ($\beta$=`r p300_na_ar_stat$estimate`, 95% CI=[`r paste0(p300_na_ar_stat$lower,", ",p300_na_ar_stat$upper)`], *p*=`r p300_na_ar_stat$p.value`); see Figure 3). SES continued to moderate the relationship between negative affect and the P3~resid~ to rejection even when covarying for EMA-assessed positive affect as a fixed effect covariate[^2], as well as when covarying for deception (see Supplement).

[^2]: Models covarying for EMA reported positive affect did not converge for models testing SES moderating relationship between negative affect and RewP~resid~ or P3~resid~ to acceptance

```{r}
## REWP
######## ACC > REJ ######## 
mean_ses <- mean(df_150275_cz_ema$ADI_NATRANK_z, na.rm=TRUE)
sd_ses <- sd(df_150275_cz_ema$ADI_NATRANK_z, na.rm=TRUE)
SES_list <- list(ADI_NATRANK_z=round(c(mean_ses + sd_ses,mean_ses - sd_ses),2)) 

m_rewp_acc <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
        zi = ~ .,
  data = df_150275_cz_ema,
  family=gaussian, REML=TRUE)

m_rewp_acc_ss <- emtrends(m_rewp_acc, pairwise ~ADI_NATRANK_z, var="AA_AR_z",at=SES_list, adjust="none")|> test()

## P3
mean_ses <- mean(df_275425_pz_ema$ADI_NATRANK_z, na.rm=TRUE)
sd_ses <- sd(df_275425_pz_ema$ADI_NATRANK_z, na.rm=TRUE)
SES_list <- list(ADI_NATRANK_z=round(c(mean_ses + sd_ses,mean_ses - sd_ses),2)) 
######## ACC > REJ ######## 
m_p300_acc <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AA_AR_z + Age_c + demo_child_sex + site + (1 | ID),
        zi = ~ .,
  data = df_275425_pz_ema,
  family=gaussian, REML=TRUE)

m_p300_acc_ss <- emtrends(m_p300_acc, pairwise ~ADI_NATRANK_z, var="AA_AR_z",at=SES_list, adjust="none")|> test()
######## REJ > ACC ######## 
# m_p300_rej <- glmmTMB(na_cubert ~ ADI_NATRANK_z*AR_AA_z + Age_c + demo_child_sex + site + (1 | ID),
#         zi = ~ .,
#   data = df_275425_pz_ema,
#   family=gaussian, REML=TRUE)
# 
# m_p300_rej_ss <- emtrends(m_p300_rej, pairwise ~ADI_NATRANK_z, var="AR_AA_z",at=SES_list, adjust="none")|> test()
```

Follow-up simple slope analyses showed that while no simple slopes were significant for the SES x RewP~resid~ interaction (*p* = `r round(min(m_rewp_acc_ss$emtrends[,6]),2)`), there were significant simple slopes for the SES x P3~resid~ such that lower SES was associated with a more negative relationship between P3~resid~ to *acceptance* and subsequent negative affect (slope = `r round(m_p300_acc_ss$emtrends[2,2],2)`, *p*=`r format.pval(m_p300_acc_ss$emtrends[2,6],eps=0.001)`), and positive relationship between P3~resid~ to *rejection* and subsequent negative affect (slope = `r m_p300_rej_ss$emtrends[2,2]`, *p*=`r format.pval(m_p300_rej_ss$emtrends[2,6],eps=0.001)`). That is, individuals with lower SES who had blunted acceptance sensitivity or heightened rejection sensitivity exhibited greater negative affect outside of the lab.

SES did not moderate the relationship between positive affect and RewP~resid~ to acceptance ($\beta$=`r rewp_pa_stat$estimate`, 95% CI=[`r paste0(rewp_pa_stat$lower,", ", rewp_pa_stat$upper)`], *p*=`r rewp_pa_stat$p.value`) or rejection ($\beta$=`r rewp_pa_ar_stat$estimate`, 95% CI=[`r paste0(rewp_pa_ar_stat$lower,", ", rewp_pa_ar_stat$upper)`], *p*=`r rewp_pa_ar_stat$p.value`), nor between positive affect and P3~resid~ to rejection ($\beta$=`r p300_pa_ar_stat$estimate`, 95% CI=[`r paste0(p300_pa_ar_stat$lower,", ", p300_pa_ar_stat$upper)`], *p*=`r p300_pa_ar_stat$p.value`). This moderation was trending for P3~resid~ to acceptance ($\beta$=`r p300_pa_stat$estimate`, 95% CI=[`r paste0(p300_pa_stat$lower,", ", p300_pa_stat$upper)`], *p*=`r p300_pa_stat$p.value`).

```{r, eval=FALSE}
performance::check_model(model_275425_ema_na_ar, data=df_275425_pz_ema, plot = TRUE)
```

# Discussion

The current study found important links between SES and neural response to social feedback---SES was (a) related to aberrant responses to peer acceptance and rejection, and (b) moderated the association between neural response to feedback and negative affect assessed outside of the lab. Follow-up analyses indicated that lower SES adolescents who had a more blunted neural response to acceptance (as indicated by a smaller P3~resid~) and greater neural response to rejection (as indicated by a larger P3~resid~) reported greater daily experiences of negative affect.

## Linking SES to psychopathology

The present study provides novel evidence of one potential mechanism through which youth SES may lead to heightened risk for internalizing disorders in adolescence. Because this data cannot determine the causal direction between SES, brain responses to peer feedback, and daily negative affect, we do not know whether changes in brain responsivity lead to daily negative affect or vice versa. One possibility is that low SES environments lead to greater negative affect [@galloUnderstandingAssociationSocioeconomic2003], which in turn leads to blunted sensitivity to acceptance and heightened sensitivity to rejection. Another possibility is that growing up in a low SES environment may make youth less sensitive to positive social feedback and more sensitive to negative social feedback, relative to their higher SES peers. Such interpersonal sensitivities may then lead to greater daily negative affect, and chronic experiences of negative affect may in turn lead to depression. Prior data most support this pathway. Numerous studies [@eisenbergerFMRIStudyCytokineinduced2009; @groschwitzDifferentialNeuralProcessing2016; @jankowskiFeelingLeftOut2018; @kumarIncreasedNeuralResponse2017; @beerAnxiouslyElaboratingSocial2016; @guyerLastingAssociationsEarlychildhood2014; @rappaportBrainResponsesSocial2020] have shown that depressed youth exhibit a blunted response to social acceptance, and anxious youth a heightened response to social rejection (though see @guNeuralCorrelatesNegative2020 and @harrewijnBehavioralEEGResponses2018 for examples of social anxiety being related to *enhanced* response to social acceptance too). Longitudinal studies have also shown that low SES prospectively predicts changes in the way youth report on their relationships [@simonsRelationalSchemasHostile2012; @simonsLearningBeBad2011], and that clinical levels of social anhedonia and rejection sensitivity cross-sectionally and prospectively predict greater depression [@llerenaSocialAnhedoniaAffiliation2012; @aydukRejectionSensitivityDepressive2001; @gaoAssociationsRejectionSensitivity2017]. Thus, these findings together with prior research suggest one intriguing explanation for how youth SES may lead to adolescent depression.

To our knowledge, only one other study examined the association between SES and neural sensitivity to feedback; the present study replicates and builds on this [@rappaportBehavioralPsychiatricCorrelates2024a]. While both studies were comparable sample sizes, age ranges, and oversampled individuals with depression, the prior study used a 1) different social feedback task than the current study and 2) different measure of SES (income-to-needs). ADI is a more reliable and objective measure of SES than income-to-needs as it is composite measure rather than a single measure and is derived from the American Community Survey rather than self-report. Finally, the present study collected a large, clinically-enriched sample from two different, diverse metro areas, and measured experience with negative affect via daily ecological momentary assessments over a week as opposed to self-report at a single timepoint.

Clinically, these findings suggest that prevention and intervention focused on increasing hedonic responses to acceptance and reducing rejection sensitivity in safe, non-threatening situations may alleviate psychopathology. For example, short-term solutions may include helping youth heal from racial trauma [e.g., @metzgerHealingInterpersonalRacial2021], or interventions aimed at cultivating positive peer interactions [@pollakSystematicReviewIntervention2023]. Longer-term solutions may involve systemic interventions focused on reducing instances of discrimination against lower SES youth [@bartlettGettingRootProblem2022].

## Strengths and Limitations

The current study has additional, noteworthy strengths. First, these findings extend previous research detailing how the brain responds to social feedback. At a group level, we show that an fMRI task of neural responses to social feedback---the Chatroom task [@pagliaccioNeuralSensitivityPeer2022; @guyerAmygdalaVentrolateralPrefrontal2008]---yields the expected ERP components: RewP and P3. We also show these components have acceptable psychometrics (split-half reliability/internal consistency and dependability). Finding that the RewP and P3 occur across this and other social feedback tasks [@weinbergNeuralResponsesSocial2021; @kujawaSocialProcessingEarly2017; @rappaportBehavioralPsychiatricCorrelates2024a; @distefanoComparisonElectrocorticalResponse2018] speaks to the generalizable role of these components in responding to rewarding and salient feedback, respectively. Additionally, we demonstrate functional specificity: that the task elicits specific processes and not brain-wide differences---ERPs to acceptance and rejection within the N100 time window did not significantly differ from each other and exhibited low internal consistency and dependability. Second, the emotional ratings assessed during the social feedback task verified that participants felt 'better' when accepted and 'worse' when rejected by peers that they were interested in chatting with (i.e., high-value peers).

The current study must also be considered in light of its limitations. First, although the area deprivation index provides a rich measure of the neighborhood youth are currently living, it does not capture other aspects of adolescents' environment such as where they spend significant time (e.g., school, after school activities). Second, we did not assess how long youth had been living at this address; it is possible that some youth had recently moved to their address (although due to low upward mobility in the USA [@chettyEconomicMobility2018] it is unlikely SES dramatically changed). Third, we did not examine how the perceived race or ethnicity of the peer giving feedback impact brain responses. Half of the feedback came from white peers, while the other half came from peers perceived to be non-white. Thus, we were unfortunately under-powered to test whether peer perceived race or ethnicity interacted with neural response to feedback. Future versions of this and other social feedback tasks with more trials from peers of different racial and ethnic backgrounds will be key to more rigorously testing for racial or ethnic group differences. Fourth, one could question the validity of labeling the ERP components we identified as a RewP and P3. These components have, however, been identified in many other studies of social feedback within similar time windows and scalp topographies [@weinbergNeuralResponsesSocial2021; @kujawaSocialProcessingEarly2017; @rappaportBehavioralPsychiatricCorrelates2024a; @distefanoComparisonElectrocorticalResponse2018], and like other studies, we found that ERPs to acceptance were significantly greater than to rejection in the RewP time window, but did not differ within the P3 time window [@rappaportBehavioralPsychiatricCorrelates2024a; @peggTimeCourseReactivity2022].

In conclusion, this study has clear implications for basic and clinical research on the role of SES in psychopathology. Recent studies are beginning to elucidate the role and consequences of SES [@correaEthnicDifferencesBehavioral2022] on not only symptoms of psychopathology, but their underlying neurobiological mechanisms as well [e.g., @sheridanChapter13Neurodevelopmental2020; @palacios-barriosPovertySelfregulationConnecting2019; @barchEarlyChildhoodSocioeconomic2022]. At the very least, accounting for SES in analyses will help assure that findings examining neural mechanisms of psychopathology are not influenced by a large potential third-variable. More broadly, studying consequences of SES can potentially influence public policies aimed at lifting at-risk children out of poverty.

\newpage

# Figures

Figure 1. A) Example of trial from chatroom task. B) Grand average ERP for acceptance and rejection feedback from high-value peers. Colored sections of the graph represent time windows where ERP components were extracted at Cz electrode: N100 = purple, RewP = orange, P3 = blue. C) Mean in-task, post-feedback emotional ratings across all trials and participants by Feedback (acceptance, rejection) and Value (high, low).

Figure 2. Relationship between SES and brain responses to acceptance (relative to rejection) for RewP~resid~ and P3~resid~ ERP components.

Figure 3. Interactions for which SES significantly moderated association between brain responses to acceptance or rejection and negative affect. Orange lines = -1 standard deviation below the mean SES; Blue lines = +1 standard deviation above the mean. RewP to acceptance: b= `r round(rewp_na_stat$estimate,3)`, p= `r round(rewp_na_stat$p.value,3)`; No simple slopes significant. P3 to acceptance: b= `r round(p300_na_stat$estimate,3)`, p= `r round(p300_na_stat$p.value,3)`; Simple slope significant for SES -1 SD. P3 to rejection: b= `r round(p300_na_ar_stat$estimate,3)`, p= `r round(p300_na_ar_stat$p.value,3)`; Simple slope significant for SES -1 SD. Note: All plots use residualized scores, such that 'Acceptance RewP' indicates responses to acceptance residualized for rejection, and vice versa.

```{r}
library(readxl)
cdrs <- readRDS(here("../data/demographics_questionnaire_5.14.24.RDS"))  %>%
  mutate(ID = as.integer(subjectID)) %>%
  select(ID, starts_with("cdrs_"))

cu_diagnostic_groups <- read_excel("/projects/p31735/BUDS/eeg_processing/ParticipantInfo/CU_Participant_Assessment_Dates.xlsx")[-1,] %>%
  mutate(ID = as.integer(src_subject_id)) %>%
  select(ID, group)

nw_diagnostic_groups <- read_excel("/projects/p31735/BUDS/eeg_processing/ParticipantInfo/NU_PREDICT_Participant_Info.xlsx")[-1,] %>%
  mutate(ID = as.integer(src_subject_id)) %>%
  select(ID, group)

diagnostic_groups <-  rbind(cu_diagnostic_groups, nw_diagnostic_groups) %>%
  left_join(cdrs, by="ID")

df_150275_cz_groups <- df_150275_cz %>%
  left_join(diagnostic_groups, by="ID") %>%
  mutate(lifetime_mdd = case_match(group, "MDD" ~ "yes",
                                          "remMDD" ~ "yes",
                                          "HC" ~ "no"))

df_275425_pz_groups <- df_275425_pz %>%
  left_join(diagnostic_groups, by="ID") %>%
  mutate(lifetime_mdd = case_match(group, "MDD" ~ "yes",
                                          "remMDD" ~ "yes",
                                          "HC" ~ "no"))


summary(lm(AA_AR_z ~ group, df_150275_cz_groups))
summary(lm(AR_AA_z ~ group, df_150275_cz_groups))
summary(lm(AA_AR_z ~ lifetime_mdd, df_150275_cz_groups))
summary(lm(AR_AA_z ~ lifetime_mdd, df_150275_cz_groups))

summary(lm(AA_AR_z ~ IDAS_depression, df_150275_cz_groups))
summary(lm(AR_AA_z ~ IDAS_depression, df_150275_cz_groups))
summary(lm(AA_AR_z ~ IDAS_anxiety, df_150275_cz_groups))
summary(lm(AR_AA_z ~ IDAS_anxiety, df_150275_cz_groups))
summary(lm(AA_AR_z ~ IDAS_wellbeing, df_150275_cz_groups))
summary(lm(AR_AA_z ~ IDAS_wellbeing, df_150275_cz_groups))

summary(lm(AA_AR_z ~ group, df_275425_pz_groups))
summary(lm(AR_AA_z ~ group, df_275425_pz_groups))
summary(lm(AA_AR_z ~ lifetime_mdd, df_275425_pz_groups))
summary(lm(AR_AA_z ~ lifetime_mdd, df_275425_pz_groups))

summary(lm(AA_AR_z ~ IDAS_depression, filter(df_275425_pz_groups, group!="HC")))
summary(lm(AR_AA_z ~ IDAS_depression, filter(df_275425_pz_groups, group!="HC")))

summary(lm(AA_AR_z ~ IDAS_wellbeing, df_275425_pz_groups))
summary(lm(AR_AA_z ~ IDAS_wellbeing, df_275425_pz_groups))
summary(lm(AA_AR_z ~ IDAS_wellbeing, filter(df_275425_pz_groups, group!="HC")))
summary(lm(AR_AA_z ~ IDAS_wellbeing, filter(df_275425_pz_groups, group!="HC")))

anova(lm(AR_AA_z ~ group, df_275425_pz_groups))
anova(lm(AR_AA_z ~ lifetime_mdd, df_275425_pz_groups))
summary(lm(AR_AA_z ~ scale(IDAS_depression, center=TRUE, scale=TRUE), df_275425_pz_groups))
summary(lm(AR_AA_z ~ scale(IDAS_depression, center=TRUE, scale=TRUE), filter(df_275425_pz_groups, group=="remMDD")))
summary(lm(AR_AA_z ~ scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, filter(df_275425_pz_groups, group!="HC")))
summary(lm(AR_AA_z ~ scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, filter(df_275425_pz_groups, group=="remMDD")))

summary(lm(AA_AR_z ~ group + scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, filter(df_150275_cz_groups, group!="MDD")))
summary(lm(AR_AA_z ~ group + scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, filter(df_150275_cz_groups, group!="MDD")))
summary(lm(AA_AR_z ~ group + scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, filter(df_275425_pz_groups, group!="MDD")))
summary(lm(AR_AA_z ~ group + scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, filter(df_275425_pz_groups, group!="MDD")))

#CDRS
summary(lm(AA_AR_z ~ cdrs_raw_i, df_150275_cz_groups))
summary(lm(AR_AA_z ~ cdrs_raw_i, df_150275_cz_groups))
summary(lm(AA_AR_z ~ cdrs_t_score_i_corrected, df_150275_cz_groups))
summary(lm(AR_AA_z ~ cdrs_t_score_i_corrected, df_150275_cz_groups))
summary(lm(AA_AR_z ~ cdrs_raw_6, df_150275_cz_groups))
summary(lm(AR_AA_z ~ cdrs_raw_6, df_150275_cz_groups))
summary(lm(AA_AR_z ~ cdrs_t_score_6_corrected, df_150275_cz_groups))
summary(lm(AR_AA_z ~ cdrs_t_score_6_corrected, df_150275_cz_groups))
summary(lm(AA_AR_z ~ cdrs_raw_12, df_150275_cz_groups))
summary(lm(AR_AA_z ~ cdrs_raw_12, df_150275_cz_groups))
summary(lm(AA_AR_z ~ cdrs_t_score_12_corrected, df_150275_cz_groups))
summary(lm(AR_AA_z ~ cdrs_t_score_12_corrected, df_150275_cz_groups))

summary(lm(AA_AR_z ~ cdrs_raw_i, df_275425_pz_groups))
summary(lm(AR_AA_z ~ cdrs_raw_i, df_275425_pz_groups))
summary(lm(AA_AR_z ~ cdrs_t_score_i_corrected, df_275425_pz_groups))
summary(lm(AR_AA_z ~ cdrs_t_score_i_corrected, df_275425_pz_groups))
summary(lm(AA_AR_z ~ cdrs_raw_6, df_275425_pz_groups))
summary(lm(AR_AA_z ~ cdrs_raw_6, df_275425_pz_groups))
summary(lm(AA_AR_z ~ cdrs_t_score_6_corrected, df_275425_pz_groups))
summary(lm(AR_AA_z ~ cdrs_t_score_6_corrected, df_275425_pz_groups))
summary(lm(AA_AR_z ~ cdrs_raw_12, df_275425_pz_groups))
summary(lm(AR_AA_z ~ cdrs_raw_12, df_275425_pz_groups))
summary(lm(AA_AR_z ~ cdrs_t_score_12_corrected, df_275425_pz_groups))
summary(lm(AR_AA_z ~ cdrs_t_score_12_corrected, df_275425_pz_groups))


sum(complete.cases(filter(df_275425_pz_groups, group=="remMDD")$IDAS_depression))

summary(lm(AR_AA_z ~ scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, filter(df_275425_pz_groups, group!="HC")))
df_no_hc <- filter(df_275425_pz_groups, group!="HC")
model1 <- lm(AR_AA_z ~ scale(IDAS_depression, center=TRUE, scale=TRUE) + Age + demo_child_sex, df_no_hc)
df_no_hc$fitted <- fitted(model1)
# Load ggplot2
library(ggplot2)

# Assuming you have a data frame called 'df' with columns 'IDAS_depression' and 'AR_AA_z'
plot1 <- ggplot(df_no_hc, aes(x = AR_AA_z, y = fitted)) +
  geom_point(color = "black", alpha = 0.6) +  # Scatter plot points
  geom_smooth(method = "lm", se = TRUE, color = "blue") +  # Add linear regression line with confidence interval
  labs(
    x = "P300 to rejection \n(residualized for acceptance)\n covarying for age and sex",
    y = "IDAS Depression"
  ) +
  theme_apa()  # Use a minimal theme

```

# References

::: {#refs custom-style="Bibliography"}
:::
